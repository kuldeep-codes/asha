<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>When it’s time to migrate data, the more you know, the easier it is to control operational complexity, and reduce costs. Your customer’s business continuity must be your priority. In this module, you will learn how to prepare data for a successful migration, by identifying important factors such as legacy systems, static, and common data.</p>
<p>In this module, you will learn how to:</p>
<ul>
<li>Choose a data integration (import/export) strategy.</li>
<li>Identify common migration scenarios and tools in finance and operations apps.</li>
<li>Work with the Bring your own database (BYOD) feature.</li>
<li>Identify relevant (legacy) systems.</li>
<li>Identify and import static data that is common between industries.</li>
<li>Create and review test plans for data migration.</li>
<li>Identify and extract source data.</li>
<li>Identify relevant data entities and elements.</li>
<li>Generate field mapping between source and target data structures.</li>
<li>Perform a test migration and validate output.</li>
<li>Support the transition between the existing and migrated systems.</li>
</ul>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Select a data integration (import/export) strategy</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>This unit explores integration patterns, scenarios, and solutions for finance and operations. Although this unit does not include technical details about how to use or set up every integration pattern or how to work with sample code, it is always wise to be aware of available integration tools.</p>
<p>The following integration patterns are available for finance and operations apps:</p>
<ul>
<li>OData</li>
<li>Batch data API</li>
<li>Custom service</li>
<li>Consume external web services</li>
<li>Excel integration</li>
</ul>
<h2 id="odata">OData</h2>
<p>OData is a standard protocol for creating and consuming data. The purpose of OData is to provide a protocol that is based on Representational State Transfer (REST) for create, read, update, and delete (CRUD) operations. OData applies web technologies such as HTTP and JavaScript Object Notation (JSON) to provide access to information from various programs.</p>
<p>OData provides the following benefits:</p>
<ul>
<li>Allowing developers to interact with data by using RESTful web services</li>
<li>Providing a simple and uniform way to share data in a discoverable manner</li>
<li>Enabling broad integration across products</li>
<li>Enabling integration by using the HTTP protocol stack</li>
</ul>
<h2 id="batch-data-api">Batch data API</h2>
<p>Use the batch data API in scenarios that require one or both Data management package REST API and Recurring integrations. Both APIs support data import scenarios and data export scenarios.</p>
<p>For finance and operations apps, we have tried to simplify this process for all parties who are involved, from integration solution builders to customer users.</p>
<p>The package API lets you integrate with finance and operations apps by using data packages. The REST API can be used with both cloud and on-premises deployments. The data management framework's package API uses OAuth 2.0 for authorizing access.</p>
<p>The process of data migration, and movement into and out of any enterprise system, are critical pieces that any platform must support.</p>
<p>Recurring integration does the following:</p>
<ul>
<li>Builds on data entities and the Data management framework</li>
<li>Enables the exchange of documents or files between finance and operations apps and any third-party application or service</li>
<li>Supports several document formats, source-mapping, and filters</li>
<li>Uses secure Representational State Transfer (REST) application programming interfaces (APIs) and authorization mechanisms to receive data from, and send data back to, integration systems</li>
</ul>
<p>Before the integrating client application can consume this endpoint, you need to create an application ID in Microsoft Entra ID and give it appropriate permission to finance and operations apps.</p>
<p>When you create and enable a recurring job, you're prompted to enter the Microsoft Entra ID application ID that will interact with that recurring job. Therefore, be sure to make a note of the application ID.</p>
<p>Much effort and planning go into building third-party integrations between an enterprise line of business (LOB) system, such as Microsoft finance and operations apps, and various source systems.</p>
<h2 id="custom-service">Custom service</h2>
<p>A developer can create custom services for finance and operations apps. When a developer writes a custom service under a service group, the service group is always deployed on two endpoints:</p>
<ul>
<li><strong>SOAP endpoint</strong> – Code examples for consuming custom services using SOAP are available in the <a data-linktype="external" href="https://github.com/Microsoft/Dynamics-AX-Integration/tree/master/ServiceSamples/SoapConsoleApplication/?azure-portal=true">Microsoft Dynamics AX Integration GitHub repository - SoapConsoleApplication</a>.</li>
<li><strong>JSON endpoint</strong> – Code examples for consuming JSON services are available in the <a data-linktype="external" href="https://github.com/Microsoft/Dynamics-AX-Integration/tree/master/ServiceSamples/JsonConsoleApplication/?azure-portal=true">Microsoft Dynamics AX Integration GitHub repository - JsonConsoleApplication</a>.</li>
</ul>
<h2 id="consume-external-web-services">Consume external web services</h2>
<p>A developer consumes web services by adding new class libraries to finance and operations apps, such as authentication, requests, and responses. This library is then referenced in the app's project and used within X++ code to enable seamless integration. You can use .NET tools like HTTPClient for REST APIs or WCF for SOAP services, ensuring proper error handling and security for sensitive data. After integrating and testing the library, the app can interact with external systems, such as payment gateways, CRMs, or analytics platforms, to extend its functionality.</p>
<h2 id="excel-integration">Excel integration</h2>
<p>The Microsoft Office integration capabilities provide users with a productive environment that helps them get the job done by using Office products. Microsoft Excel can change and quickly analyze data.</p>
<p>The Excel Data Connector app interacts with Excel workbooks and OData services that are created for publicly exposed data entities. The Excel Data Connector add-in enables Excel to become a seamless part of the user experience. The Excel Data Connector add-in is built by using the Office Web add-ins framework. The add-in runs in a task pane.</p>
<h2 id="synchronous-vs-asynchronous-integration-patterns">Synchronous vs. asynchronous integration patterns</h2>
<p>Processing can be either synchronous or asynchronous. Often, the type of processing that you must use determines the integration pattern that you choose.</p>
<p>A synchronous pattern is a blocking request and response pattern, where the caller is blocked until the recipient has finished running the Excel integration and gives a response. An asynchronous pattern is a non-blocking pattern, where the caller submits the request and then continues without waiting for a response.</p>
<p>We recommend using <strong>OData</strong> for synchronous and <strong>Batch data API</strong> for asynchronous integration scenarios.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Common migration scenarios and tools</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>The following are two scenarios, and recommendations for which integration pattern to use.</p>
<h2 id="scenario-1">Scenario 1</h2>
<p>An energy company has field workers who schedule installation jobs for heaters. This company uses finance and operations apps for the back office and third-party software as a service (SaaS) to schedule appointments. When field workers schedule appointments, they must look up inventory availability to make sure that installation parts are available for the job.</p>
<p>The real-time data required:</p>
<ul>
<li>Peak data volume is 1,000 records per hour</li>
<li>Frequency is Ad hoc.</li>
</ul>
<p>This scenario can be implemented by using a custom service integration pattern.</p>
<p>In finance and operations, have a developer create a custom service to calculate the physical on-hand inventory for a given item.</p>
<p>In the scheduling application, make a real-time call to a custom service endpoint, through either SOAP or REST, to retrieve inventory information for the selected item.</p>
<h2 id="scenario-2">Scenario 2</h2>
<p>A company receives a large volume of sales orders from a front-end system that runs on-premises. Periodically, these orders must be sent to finance and operations for processing and management.</p>
<p>The real-time data is not required. Peak data volume is 20,000 records per hour and the Frequency is One time every five minutes.</p>
<p>This scenario is best implemented by using a batch data APIs integration pattern.</p>
<p>Determine all the entities that are required for the integration, and make sure that data management is enabled for the entities.</p>
<h2 id="finance-and-operations-apps-integration-tools">Finance and operations apps integration tools</h2>
<p>Finance and operations apps offer tools for data migration, such as:</p>
<ul>
<li>Data management workspace</li>
<li>Office integration</li>
<li>Excel workbook designer</li>
</ul>
<p>To learn more about API technology for finance and operations apps, see the <a data-linktype="absolute-path" href="/en-us/training/modules/integrate-azure-finance-operations/?azure-portal=true">Integrate finance and operations apps with Microsoft Azure</a>, and <a data-linktype="absolute-path" href="/en-us/training/modules/data-package-api-finance-operations/?azure-portal=true">Implement the Data management package API for finance and operations apps</a> modules.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Bring your own database (BYOD)</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>The BYOD feature lets administrators configure their own database, and then export one or more data entities, that are available in finance and operations apps, into it. Specifically, this feature lets you complete the following tasks:</p>
<ul>
<li>Define one or more Microsoft Azure SQL databases that you can export entity data from finance and operations apps into.</li>
<li>Export either all the records (full push) or only the records that have changed or been deleted (incremental push).</li>
<li>Use the rich scheduling capabilities of the batch framework to enable periodic exports.</li>
<li>Access the entity database by using Transact-SQL (T-SQL), and even extend the database by adding more tables.</li>
<li>Export entities into multiple databases.</li>
</ul>
<p>The BYOD feature is recommended for when you do the following:</p>
<ul>
<li>Export data from finance and operations apps into your own data warehouse.</li>
<li>Use analytical tools other than Power BI, and those tools require T-SQL access to data.</li>
<li>Perform batch integration with other systems.</li>
</ul>
<p>If you have integration solutions that require direct T-SQL access to the database, BYOD is the recommended upgrade path.</p>
<p>Before you can configure the export option and use the BYOD feature, you must create an SQL database for production environments by using Azure portal.</p>
<div class="mx-imgBorder">
<p><a data-linktype="relative-path" href="media/azure-side-bar.png#lightbox"><img alt="Screenshot of the Azure portal SQL databases menu item." data-linktype="relative-path" src="./rawmb500/media_azure_side_bar.png"/></a></p>
</div>
<p>You should also create a SQL user account for sign-in to the database. Make sure to record and save the server name, database name, and the SQL user ID and password. You will use these values when you configure the entity export option.</p>
<p>If you're using the BYOD feature for integration with a business intelligence (BI) tool, consider creating an SQL premium database. Premium databases support clustered columnstore indexes (CCIs). CCIs are in-memory indexes that improve the performance of read queries that are typical in analytical and reporting workloads.</p>
<p>If you're using the BYOD feature to export data into a staging database or for general integration purposes, you can use a standard database.</p>
<p>To configure the entity export, follow this procedure.</p>
<ol>
<li><p>Go to the <strong>Data management</strong> workspace and select the <strong>Configure entity export to database</strong> tile.</p>
<div class="mx-imgBorder">
<p><a data-linktype="relative-path" href="media/configure-entity.png#lightbox"><img alt="Screenshot of the Configure entity export to database tile." data-linktype="relative-path" src="./rawmb500/media_configure_entity.png"/></a></p>
</div>
</li>
<li><p>If you've already configured any databases, a list is shown, and you will need to select a database. Then, skip step 3.</p>
</li>
<li><p>To configure a new database, select <strong>New</strong>, and then enter a unique name and a description for the new database.</p>
</li>
<li><p>Enter the connection string in the following format: <strong>Data Source</strong>=&lt;logical server name&gt;, <strong>1433</strong>; <strong>Initial Catalog</strong> =&lt;your DB name&gt;; <strong>Integrated Security</strong>=False; <strong>User ID</strong> = &lt;SQL user ID&gt;; <strong>Password</strong> = &lt;password&gt;</p>
</li>
<li><p>Select <strong>Validate</strong>, and make sure that the connection is successful.</p>
<p>When the validation is passed, the database that you configured for entity export appears in lists of databases.</p>
</li>
<li><p>By default, the <strong>Create clustered column store indexes</strong> option is enabled. This option optimizes the destination database for selected queries by defining CCIs for entities that are copied from finance and operations.</p>
</li>
<li><p>By default, the <strong>Enable triggers in target database</strong> option is disabled. This option sets export jobs to enable SQL triggers in the target database, and lets you hook downstream processes into the trigger to orchestrate actions that must be started after records have been inserted.</p>
</li>
<li><p>You can now publish one or more entities to the new database by selecting the <strong>Publish</strong> option on the menu.</p>
</li>
</ol>
<p>After entities are published to the destination database, you can use the <strong>Export</strong> function in the <strong>Data management</strong> workspace to move data. The <strong>Export</strong> function lets you define a <strong>Data movement</strong> job that contains one or more entities.</p>
<p>You can use the <strong>Export</strong> page to export data from finance and operations apps into many target data formats, such as a comma-separated values (CSV) file. This page also supports SQL databases as another destination.</p>
<p>The value of the &lt;logical server name&gt; has a format like &lt;yourSqlAzureServername&gt; .<strong>database.windows.net</strong>, which can be found in Azure portal by selecting the SQL databases menu.</p>
<p>For scenarios in which reporting systems read data from BYOD, there is always the challenge of ensuring that the reporting systems get consistent data from BYOD while the sync from finance and operations apps is in progress.</p>
<p>One trigger is supported per bulk insert operation. The size of the bulk insert is determined by the <strong>Maximum insert commit size</strong> parameter in the Data management framework.</p>
<p>You can achieve this result by not having the reporting systems read directly from the staging tables that were created by the BYOD process. The staging tables hold the data while data is being synced from the finance and operations apps instance and hence will be constantly changing.</p>
<p>Use the SQL trigger feature to determine when the data sync from finance and operations apps has been completed, and then hydrate the downstream reporting systems.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Test a data migration and validate output</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>To prepare for data migration, the first step is to identify relevant (legacy) systems that the customer is currently using. Then, you need to identify and import static data that is common between industries.</p>
<p><img alt="Diagram of the steps to Migrate data and validate output." data-linktype="relative-path" src="./rawmb500/media_data_migrate.png"/></p>
<h2 id="identify-relevant-legacy-systems">Identify relevant (legacy) systems</h2>
<p>A legacy system is a business solution that has a few common characteristics with current solutions in the market, such as being based on outdated technology or design, being incompatible or difficult and costly to integrate with current systems, and a potential inability of being purchased from vendors because it is unavailable and discontinued.</p>
<p>Each legacy system might have a different data export format option that must be considered as part of the planning for data migration, and you should be prepared for data extraction from legacy data sources.</p>
<h2 id="identify-and-import-static-data-that-is-common-between-industries">Identify and import static data that is common between industries</h2>
<p>Your customer might have different verticals, such as distribution and trade, manufacturing, and retail. Even if you manage a customer’s data migration that is only focused on one specific industry, such as manufacturing, you still need to investigate to determine whether their customers and suppliers who might be in a different industry such as resellers which are retailers who interchange data with your customer.</p>
<p>When you plan data migration, you need to identify common data that are not frequently changed, such as country codes, zip or postal codes, states, or regions.</p>
<p>Identifying the common static data between different verticals or industries helps reduce the cost and prepare the source data, clean it, and get customer consensus prior to importing the data to finance and operations apps.</p>
<h2 id="create-and-review-test-plans-for-data-migration">Create and review test plans for data migration</h2>
<p>Your plans for data migration need to be ready to guide you through the process. Make sure that the right system permissions are applied on resources to have a successful data migration.</p>
<p>Make sure that you back up the database and source files that you plan to migrate. If you encounter any issues during migration, such as corrupt, incomplete, or missing files, you need to correct the error and restore the database from the backup.</p>
<p>You need to extract all data from the source system, and then migrate the data to the target, which is finance and operations apps. Then, you need to clean the data and transform it into the proper format for transfer to finance and operations apps.</p>
<p>Finally, load your cleaned and deduplicated data into your finance and operations apps data management, map fields, and import data to finance and operations apps.</p>
<p>Make sure to always monitor your data migration during the process so that you can detect and resolve any issues or problems if they arise.</p>
<p>Once the migration is complete, ensure that there are no connectivity problems with source system and finance and operations. Your goal is to make sure that all data correctly migrated by performing unit, system, regression, and other applicable tests. Do not forget the simplest method, which is using built-in reports and inquiries in finance and operations, and then have the customer’s key stakeholder verify the data and compare the migrated data with their legacy system.</p>
<p>For example, assume you are migrating the chart of accounts, posted transactions, and so on. After you migrated data for a specific financial period, you ran the trial balance print, and then asked the CFO (or one of your customer’s financial leaders) to compare the results and match them against the financial report on their legacy system before migrating the next period.</p>
<h2 id="identify-and-extract-source-data">Identify and extract source data</h2>
<p>When you and your team have analyzed the data and retrieved relevant information from data sources (like a database) in a specific pattern, it is then time to extract the relevant data. You might need to perform further data processing, which involves adding metadata and other data integration, another process in the data workflow.</p>
<h2 id="identify-relevant-data-entities-and-elements">Identify relevant data entities and elements</h2>
<p>You need to know what sources of data are important for the analysis. If the information being analyzed is only related to the scenario at hand, it should be set aside because you should only use data sources that are absolutely relevant to the scenario for migration.</p>
<p>You should never bring all the data from multiple data sources to finance and operations apps in one occurrence; rather, you should have a proper plan to guide you according to the business scenario.</p>
<p>For example, if you are planning to bring all the purchase orders in to finance and operations apps from a legacy system, there are many related and relevant entities that you should consider as well, such as vendor groups, vendors, tax codes, headers and lines of purchase orders, and many more.</p>
<p>Prior to starting the data migration process, identify what data you’re migrating, what format it’s currently in, where it lives, and what format it should be in post-migration. Consider whether the data migration will interfere with normal business operations or will contribute to downtime. If so, you need to plan off hours or weekends for the migration process. Also, remember to perform the database backup prior to starting the data migration. You need to communicate the potential downtime with your customer, so they can plan accordingly. Remember that business continuity always should be your first priority.</p>
<p>Often, your source data must be changed and cleaned, or even split into more segments. Data verification helps you check that the data is available, accessible, complete, and in the correct format. This is called data cleansing. The first stage in data cleansing is to define which rules must be carried out manually and which need to be planned as automated.</p>
<p>Typically, manual cleansing will be done before migration starts, while automated cleansing might be done before or as part of the migration’s initial phase.</p>
<h2 id="generate-field-mapping-between-source-and-target-data-structures">Generate field mapping between source and target data structures</h2>
<p>First, you need to identify the format of the data source. You can view the formats in Data management from the <strong>Configure data source</strong> tile.</p>
<p><img alt="Screenshot of the Configure Data Source tile." data-linktype="relative-path" src="./rawmb500/media_configure_data_source.png"/></p>
<p>In <strong>Configure data source</strong>, you can create and modify sources of data for migrations. If you have identified the data sources and their relevant entities, you can use different types of data sources depending on the format exported from external systems, some of which are legacy systems.</p>
<p><a data-linktype="relative-path" href="media/data-source-types.png#lightbox"><img alt="Screenshot of the Data Source Types list." data-linktype="relative-path" src="./rawmb500/media_data_source_types.png"/></a></p>
<p>Upon adding an entity into the Data management project for either import or export, finance and operations apps creates field mapping between the source data and the target table for each data entity, which matches the schema of the table associated with the data entity.</p>
<div class="mx-imgBorder">
<p><a data-linktype="relative-path" href="media/maps-1.png#lightbox"><img alt="Screenshot of the Map Entity source to target page." data-linktype="relative-path" src="./rawmb500/media_maps_1.png"/></a></p>
</div>
<p>The type of the field, and whether it is a required field, are examples of the metadata of the table that is being shown in the <strong>Mapping details</strong> tab. Here, you can choose to ignore blank values and select a text identifier to properly use the text values from the source data field.</p>
<p>Alternatively, you can use the label for the enumerator fields instead of its value.</p>
<div class="mx-imgBorder">
<p><a data-linktype="relative-path" href="media/maps-details.svg#lightbox"><img alt="Screenshot of the Map staging to target page details." data-linktype="relative-path" src="./rawmb500/media_maps_details.png"/></a></p>
</div>
<h2 id="support-the-transition-between-the-existing-and-migrated-systems">Support the transition between the existing and migrated systems</h2>
<p>Analyzing the data between what is in the legacy system and what has been imported to finance and operations apps is an important part of data migration. This provides an overview of the source data and its corresponding target table that is represented by data entities in finance and operations apps.</p>
<p>It’s important to know how each system works and how the data within each system is structured. You also need to validate the information discovered in the analysis phase of each phase in data migration, and then ensure that all data is properly migrated by running certain reports, or inquiries. By validating the data, your team can focus solely on structural manipulation and movement and data assurance.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Check your knowledge</h1>
<div hidden="" id="module-unit-notification-container"></div>
<h2>Answer the following questions to see what you learned</h2>
<form aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>Which of the following options enables broad integration between finance and operations apps and other products, systems, and applications?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Excel integration</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Custom service</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>OData</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>Which of the following options enables the exchange of documents or files between finance and operations apps and any external application or service?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Excel integration</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Custom service</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Batch data API</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>The Excel Data Connector app interacts with Microsoft Excel workbooks through which one of the following options?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>External web services</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Custom service</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>OData</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-4" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-4">
<span class="font-weight-semibold">4.</span>
<p>An energy company has field workers who schedule installation jobs for heaters. This company uses finance and operations apps for the back office and other software as a service (SaaS) to schedule appointments. When field workers schedule appointments, they must look up inventory availability to make sure that installation parts are available for the job. The real-time data is required. Peak data volume is 1,000 records per hour and the frequency is Ad hoc. Which one of the following integration patterns should you use?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-0">
<input class="radio-dot choice-input" id="quiz-choice-3-0" name="3" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>External web services</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-1">
<input class="radio-dot choice-input" id="quiz-choice-3-1" name="3" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Excel integration</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-2">
<input class="radio-dot choice-input" id="quiz-choice-3-2" name="3" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Custom service</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-5" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-5">
<span class="font-weight-semibold">5.</span>
<p>You need to enable an exchange of documents between finance and operations apps and an external application at the end of each day. Which of the following would you implement?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-0">
<input class="radio-dot choice-input" id="quiz-choice-4-0" name="4" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Excel data connector app</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-1">
<input class="radio-dot choice-input" id="quiz-choice-4-1" name="4" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Recurring integration</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-2">
<input class="radio-dot choice-input" id="quiz-choice-4-2" name="4" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Synchronous integration</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>This module explained how to identify common migration scenarios and import static data that is common between industries. You learned about some of the tools in finance and operations apps, such as Data management and the BYOD feature.</p>
<p>As part of selecting a data integration (import/export) strategy, you were able to observe how important it is to identify relevant (legacy) systems, create, and review test plans for data migration. You also learned about identifying and extracting source data, and its relevant data entities and elements.</p>
<p>Finally, you learned that an important responsibility for the data migration team includes generating field mapping between source and finance and operations apps data entities, performing a test migration and validating the output, and then supporting the transition between the existing and migrated systems.</p>
<p>To learn more about the use cases and limitations for the migration tool, see <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/data-entities/data-management-integration-data-entity/?azure-portal=true">Data management and integration by using data entities overview</a>.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>This module discusses fundamental principles of the Data Management Platform, an important aspect of finance and operations apps. The platform's capabilities include importing and exporting data, managing data entities and data entity packages, and using asynchronous recurring integration features.</p>
<p>Imagine you are a data manager in a large multinational corporation. Your daily tasks involve handling vast amounts of data, migrating data from legacy systems, and ensuring seamless data integration across various departments. However, you often encounter challenges in managing data entities, understanding the impact of configuration keys on these entities, and sequencing data entities based on their relationships.</p>
<p>This module provides you with the knowledge and skills to overcome these challenges and efficiently manage your organization's data.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Data management concepts</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>The data management framework consists of the following concepts:</p>
<ul>
<li><p><strong>Data entities</strong> – A data entity is a conceptual abstraction and encapsulation of one or more underlying tables. A data entity represents a common data concept or functionality, such as customers or vendors. Data entities are intended to be easily understood by users who are familiar with business concepts. After data entities are created, you can reuse them through the Excel add-in, use them to define import/export packages, or use them for integrations.</p>
</li>
<li><p><strong>Data project</strong> – A data project is automatically created when you select <strong>Import</strong> or <strong>Export</strong> from the workspace and should have at least one job. It contains configured data entities, which include mapping and default processing options. A data project allows users to set up the entities that should be part of the project and defines the format that is used for each entity. It allows users to define the mapping that is used from the source file to the staging and to specify the default processing options.</p>
</li>
<li><p><strong>Data job</strong> – Use a data job to perform the actual import or export operation. A data job contains an execution instance of the data project, uploaded files, the schedule or recurrence information, and the processing options to use for the job.</p>
<p>A data job is created when the import or export operation is performed. The data job creates an instance of the data project and then runs it. If you're doing an unplanned import or export, then only one job for each data project typically exists. If it's being done multiple times with different data, then you can use the same data project to import data multiple times by using different jobs.</p>
<p>Each data project can have one or more data jobs. For instance, if you're doing a single unplanned data import, then you might have one file that is being imported. In this case, a single data project will have one data job.</p>
<p>Another scenario to consider is if you're importing data by using the same data project multiple times but with different data. In this case, more than one data job can exist for a single data project. Each data job can have one or more job histories.</p>
<p>For instance, a data job might be run multiple times after errors have been fixed. The job history describes the details, such as the time taken to run the job, the number of records processed, and the errors that occurred during processing.</p>
</li>
<li><p><strong>Job history</strong> – Histories of source to staging and staging to target jobs. After a job has been run, you can view the job history, which contains the run history for each execution run of the data job and the history of the data move from source to staging and from staging to target.</p>
<p>The <strong>Job history</strong> tab in the <strong>Data management</strong> workspace shows all job histories for the import and export data projects. From <strong>Job history</strong>, you can view the run history for the source to staging and staging to target steps. Each project can have multiple jobs, which in turn have executions. By using the job history, you can view the execution details and determine the time that it took to run the job, the number of records that were processed, and so on.</p>
</li>
<li><p><strong>Data package</strong> – Data packages are key concepts for many application lifecycle management (ALM) scenarios, such as copy configuration and data migration. A data package is a single compressed file that contains a data project manifest and data files. A data package is generated from a data job and is used for the importing or exporting of multiple files with the manifest. After you've defined a data project, including the data entities and the mapping and sequencing between these data entities, you can create a data package. Then, you can use the data package to move the definition of the data project from one environment to another.</p>
<p>You can generate a data package from a data job. To create a data package, go to the <strong>Data management</strong> workspace, load the project that you want to create the data package for, and then select <strong>Download</strong>. This process will generate a zip file.</p>
<p><a data-linktype="relative-path" href="media/dm-1.png#lightbox"><img alt="Screenshot showing the Download option to create a data package." data-linktype="relative-path" src="./rawmb500/media_dm_1.png"/></a></p>
<p>The zip file contains the package header and the manifest. The manifest defines the settings of the data project. You can use the data package to copy the settings of your data project from one environment to another.</p>
</li>
</ul>
<h2 id="data-management-platform">Data management platform</h2>
<p>By using the data management framework, you can quickly migrate reference, master, and document data from legacy or external systems. The framework provides features that help you import data into a staging environment, perform basic data quality services or validation operations on the data, and validate and cleanse the data.</p>
<p>With the data management platform features, you can map data from input to the target and do pre and post-processing on data. If you export data, the source is finance and operations apps, and if you import data, the target is finance and operations apps.</p>
<p>The framework is intended to help you quickly migrate data by using the following features:</p>
<ul>
<li>You can select only the entities that you need to migrate.</li>
<li>If an import error occurs, you can skip selected records and choose to proceed with the import by using only the good data, opting then to fix and import the bad data later. You'll be able to partially continue and use errors to quickly find bad data.</li>
<li>You can move data entities straight from one finance and operations apps system to another, without having to go through Excel or XML.</li>
<li>Data imports can be scheduled by using a batch, which offers flexibility when it's required to run. For example, you can migrate customer groups, customers, vendors, and other data entities in the system anytime.</li>
</ul>
<p>The data management framework supports using data entities in the following core data management scenarios:</p>
<ul>
<li><strong>Data migration</strong> – You can migrate reference, master, and document data from legacy or external systems.</li>
<li><strong>Set up and copy configurations</strong> – Use this scenario to copy configurations between companies or environments and set up processes or modules by using the Lifecycle Services environment.</li>
<li><strong>Integration</strong> – Use this scenario when you need real-time, service-based integration or when you need an asynchronous integration. The real-time integration doesn't have a staging area and is directly processed by the services layer.</li>
</ul>
<h2 id="data-migration">Data migration</h2>
<p>Data migration is an initial or unplanned data load that you can perform manually by using the user interface. A scenario where this pattern might be used is when a functional user has some data in a source, such as an Excel workbook that needs to be imported from a legacy system to finance and operations apps during data migration.</p>
<h2 id="data-flow">Data flow</h2>
<p>The first step is to load the file from the source to the central storage, such as Azure. Then, the data import/export framework picks up the data from the central storage and then pushes it into the staging tables of finance and operations apps. From staging, the data is moved to the target by using data entities that have been defined. This flow of data can be done row-by-row or by using a set base of the data entities for the entire underlying tables for each data entity. You can control the sequence and order in which the target tables will be populated by using the sequence entity feature of finance and operations apps.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Use data entities for data management and integration</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>Data entities provide conceptual abstraction and encapsulation (de-normalized view) of underlying table schema that represent data concepts and functionalities.</p>
<p>After data entities are created, you should be able to reuse them for Excel add-ins, import and export, or integration scenarios. A data entity is an abstraction from the physical implementation of database tables.</p>
<p>This image presents data entity integration scenarios.</p>
<p><img alt="Diagram of data entity integration scenarios." data-linktype="relative-path" src="./rawmb500/media_data_entity.png"/></p>
<p>For example, in normalized tables, a lot of the data for each customer might be stored in a customer table, and then the rest might be spread across a small set of related tables. In this case, the data entity for the customer concept appears as one de-normalized view, in which each row contains all the data from the customer table and its related tables.</p>
<p>A data entity encapsulates a business concept into a format that makes development and integration easier. The abstracted nature of a data entity can simplify application development and customization. Later, the abstraction also insulates application code from the inevitable churn of the physical tables between versions.</p>
<p>A data entity has the following capabilities:</p>
<ul>
<li>It provides a single stack to capture business logic, enable scenarios such as import and export, and integration, and support additional logics by a developer adding code.</li>
<li>It becomes the primary mechanism for exporting and importing data packages for Application Lifecycle Management (ALM) and demo data scenarios.</li>
<li>It can be exposed as OData services, and then used in tabular-style synchronous integration scenarios and Microsoft Office integrations.</li>
</ul>
<h2 id="entity-example">Entity example</h2>
<p>A consumer wants to access data that is related to a customer object, but this data is currently scattered across multiple normalized tables, such as <strong>DirParty, CustTable, LogisticsPostalAddress</strong>, and <strong>LogisticsElectronicAddress</strong>.</p>
<p>Therefore, the process of reading and writing customer data is tedious. Instead, the following customer entity can be designed to encapsulate the entire underlying physical schema into a single de-normalized view. This enables simpler read and write operations, and enables abstraction of any internal interaction between the tables.</p>
<h2 id="categories-of-entities">Categories of entities</h2>
<p>Entities are categorized based on their functions and the type of data that they serve. The following are five categories for data entities:</p>
<ul>
<li>Parameters</li>
<li>Reference</li>
<li>Master</li>
<li>Document</li>
<li>Transactions</li>
</ul>
<h3 id="parameters">Parameters</h3>
<ul>
<li>Functional or behavioral parameters.</li>
<li>Required to set up a deployment or a module for a specific build or customer.</li>
<li>Can include data that is specific to an industry or business. The data can also apply to a broader set of customers.</li>
<li>Tables that contain only one record, where the columns are values for settings. Examples of such tables exist for Accounts payable (AP), General ledger (GL), client performance options, workflows, and so on.</li>
</ul>
<h3 id="reference">Reference</h3>
<ul>
<li>Simple reference data, of small quantity, that is required to operate a business process.</li>
<li>Data that is specific to an industry or a business process.</li>
<li>Examples include units, dimensions, and tax codes.</li>
</ul>
<h3 id="master">Master</h3>
<ul>
<li>Data assets of the business. Generally, these are the "nouns" of the business, which typically fall into categories such as people, places, and concepts.</li>
<li>Complex reference data, of large quantity. Examples include customers, vendors, and projects.</li>
</ul>
<h3 id="document">Document</h3>
<ul>
<li>Worksheet data that is converted into transactions later.</li>
<li>Documents that have complex structures, such as several line items for each header record. Examples include sales orders, purchase orders, open balances, and journals.</li>
<li>The operational data of the business.</li>
</ul>
<h3 id="transactions">Transactions</h3>
<ul>
<li>The operational transaction data of the business.</li>
<li>Posted transactions. These are non-idempotent items such as posted invoices and balances. Typically, these items are excluded during a full dataset copy.</li>
<li>Examples include pending invoices.</li>
</ul>
<h2 id="configuration-keys-and-data-entities">Configuration keys and data entities</h2>
<p>Before you use data entities to import or export data, we recommended that you first determine the impact of configuration keys on the data entities that you are planning to use.</p>
<p>To learn more about configuration keys in finance and operations apps, refer to the <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/sysadmin/license-codes-configuration-keys-report/?azure-portal=true">License codes and configuration keys report</a>.</p>
<h3 id="configuration-key-assignments">Configuration key assignments</h3>
<p>Configuration keys can be assigned to one or all of the following artifacts.</p>
<ul>
<li>Data entities</li>
<li>Tables used as data sources</li>
<li>Table fields</li>
<li>Data entity fields</li>
</ul>
<h2 id="supported-integrations">Supported integrations</h2>
<p>Data management by using data entities can support the following integrations:</p>
<ul>
<li><strong>Synchronous service (OData)</strong> – Data entities enable public application programming interfaces (APIs) on entities to be exposed, which enables synchronous services. This method is used for Office integration and third-party mobile app integrations</li>
<li><strong>Asynchronous integration</strong> – Data entities also support asynchronous integration through a data management pipeline. This enables asynchronous and high-performing data insertion and extraction scenarios. This method is used for interactive file-based import/export and recurring integrations.</li>
<li><strong>Business intelligence</strong> – By using the aggregate measures available in finance and operations apps, built-in controls such as charts and integration with Microsoft Power Platform, provides reports to offer insights to business data.</li>
</ul>
<h2 id="data-migration-from-legacy-or-external-systems">Data migration from legacy or external systems</h2>
<p>After the initial deployment is up and running, the system implementer will migrate existing data assets of the customer into finance and operations apps, such as:</p>
<ul>
<li>Master data (for example, customers and vendors)</li>
<li>Subsets of documents (for example, sales orders)</li>
</ul>
<p>You can use the data management framework to copy configurations between companies or environments, and configure processes or modules by using Lifecycle Services.</p>
<p>Copying configurations is intended to make it easier to start a new implementation, even if your team doesn't deeply understand the structure of data that needs to be entered, data dependencies, or which sequence to add data to an implementation.</p>
<p>The data management framework allows you to:</p>
<p>Move data between two similar systems.</p>
<ul>
<li>Discover entities and dependencies between entities for a given business process or module.</li>
<li>Maintain a reusable library of data templates and datasets.</li>
<li>Use data packages to create incremental data entities. Data entities can be sequenced inside the packages. You can name data packages, which can be easily identifiable during import or export. When building data packages, data entities can be mapped to staging tables in grids or by using a visual mapping tool. You can also drag-and-drop columns manually.</li>
<li>View data during imports, so you can compare data and ensure that it is valid.</li>
</ul>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Work with the Data management workspace</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>This unit explains how to work with the <strong>Data management</strong> workspace in finance and operations apps.</p>
<p>The <strong>Data management</strong> workspace provides access to important tasks for data management. It also provides information about projects and project execution tasks.</p>
<p>After you've created a configuration data project, it appears in the <strong>Data projects</strong> grid in the <strong>Data management</strong> workspace.</p>
<p>For each project, the type of configuration (import or export) and the project category (Project, Configuration, Integration, or Other) are shown. Use the options to the left of the grid to filter by the appropriate project. The project definition is shared across legal entities</p>
<p><a data-linktype="relative-path" href="media/data-management.png#lightbox"><img alt="Screenshot of the Data management workspace." data-linktype="relative-path" src="./rawmb500/media_data_management.png"/></a></p>
<p>To open a project, select the project, and then select <strong>Load project</strong> to open the <strong>Import</strong> or <strong>Export</strong> page. Use the <strong>Delete</strong> button to delete the selected projects.</p>
<p><a data-linktype="relative-path" href="media/load-project.png#lightbox"><img alt="Screenshot of the Data projects page with Load project highlighted." data-linktype="relative-path" src="./rawmb500/media_load_project.png"/></a></p>
<p>You can also download the project definitions by using the <strong>Download</strong> button. Use <strong>Job history</strong> to find more details about the projects that you've run. Use the data range filters to filter by the dates when data projects were run. You can view execution details by selecting a job and then using the <strong>Execution details</strong> menu.</p>
<p><a data-linktype="relative-path" href="media/project-1.png#lightbox"><img alt="Screenshot with the Import, Job history and Download buttons highlighted." data-linktype="relative-path" src="./rawmb500/media_project_1.png"/></a></p>
<p>For export tasks, you can also download the data from the workspace by using the <strong>Download page</strong> button. The available projects in the <strong>Data management</strong> workspace are as follows:</p>
<ul>
<li>Export</li>
<li>Import</li>
<li>Copy into legal entity</li>
</ul>
<p>The <strong>All projects</strong> option is a filter to decide which type of project in the workspace to work with.</p>
<p><a data-linktype="relative-path" href="media/data-projects.png#lightbox"><img alt="Screenshot of the Data project operations type drop down list." data-linktype="relative-path" src="./rawmb500/media_data_projects.png"/></a></p>
<h2 id="sequencing">Sequencing</h2>
<p>Two types of sequencing should be considered when you are working with data entities.</p>
<ul>
<li>Sequencing data entities within a data package</li>
<li>Sequencing the order of data package imports</li>
</ul>
<h2 id="sequence-data-entities-within-a-data-package">Sequence data entities within a data package</h2>
<ol>
<li><p>When a user adds data entities to a data project, by default, a sequence is set for the order in which the entities will load. The first entity added to the project will be set as the first entity to load, the next entity added will be second, the next entity will be third, and so on.</p>
</li>
<li><p>For example, if a user added two entities in this order, <strong>Sales tax codes</strong> and <strong>Sales Tax groups</strong>, then <strong>Sales tax codes</strong> is assigned an entity sequence of <strong>1.1.1</strong>, and <strong>Sales tax groups</strong> is assigned an entity sequence of 1.1.2. The sequence level indicates that the second entity will not start the import process until the first level is finished.</p>
</li>
<li><p>To view or edit a sequence, select the <strong>Entity sequence</strong> button (available only in Standard view) on the Action Pane of the data project.</p>
</li>
<li><p>In the Definition group entity sequence, you can view the execution units and the sequence. You can change sequence by selecting the data entity in the list, setting a different Execution unit or Sequence in level, and then selecting <strong>Update selected</strong>. After selecting <strong>Update selected</strong>, the entity will move up or down in the entity list.</p>
<p><a data-linktype="relative-path" href="media/data-project-entity-seq.png#lightbox"><img alt="Screenshot highlighting the data project entity sequence." data-linktype="relative-path" src="./rawmb500/media_data_project_entity_seq.png"/></a></p>
<p>To continue with the example in step 2, to successfully import sales tax codes and groups, the sales tax codes and details have to be loaded before sales tax groups can be imported. Sales tax codes and groups are all in Execution unit = 1, but the sequences are in the order that they will be imported. Other related sales tax entities that are not dependent upon other data entities being loaded are included in the package.</p>
<p>For example, the sales tax exempt numbers entity is set in its own Execution unit = 2. This data entity will start loading immediately because there are no dependencies on other entities loading before it.</p>
<p>Finance and operations apps can determine the sequences of selected data entities in a project by selecting the <strong>Auto sequence</strong> button.</p>
</li>
</ol>
<h2 id="sequence-data-package-imports">Sequence data package imports</h2>
<p>To successfully load data, it's important to set the correct order for importing data packages because of dependencies that exist within and across modules. There is a suggested numbering format that has been created for the data packages within Lifecycle Services, so you can identify which data packages you need to load first.</p>
<p>This could be as follows:</p>
<ul>
<li>First segment: Module</li>
<li>Second segment: Data type (setup, master, transaction)</li>
<li>Third segment: Sequence number</li>
</ul>
<h2 id="mapping">Mapping</h2>
<p>When you are working with data entities, mapping an entity to a source is automatic. The automatic mapping of fields can be overridden, if needed.</p>
<p>To view how an entity is mapped, locate the tile for the entity in the project, and then select <strong>View map</strong>.</p>
<p><a data-linktype="relative-path" href="media/view-map.png#lightbox"><img alt="Screenshot highlighting the View map field." data-linktype="relative-path" src="./rawmb500/media_view_map.png"/></a></p>
<p>The Data management framework provides a mapping visualization view (default) and a mapping details view. A red asterisk (*) identifies any required fields in an entity. These fields must be mapped for you to be able to work with the entity. Other fields can be unmapped as required when you are working with the entity.</p>
<ul>
<li>To unmap a field, highlight the field in either column (<strong>Entity</strong> or <strong>Source</strong>), select <strong>Delete selection</strong>, and then select <strong>Save</strong>. After the changes are saved, close the form to return to the project.</li>
</ul>
<p>After import, you can also edit the field mapping from source to staging by using the same process.</p>
<p><a data-linktype="relative-path" href="media/map-1.png#lightbox"><img alt="Screenshot of the Map source to staging page showing the Mapping visualization view." data-linktype="relative-path" src="./rawmb500/media_map_1.png"/></a></p>
<h2 id="regenerate-a-map">Regenerate a map</h2>
<p>If you have extended an entity (added fields) or if the automatic mapping appears to be incorrect, the mapping of the entity can be regenerated in the <strong>Mapping</strong> page.</p>
<ol>
<li>To do this, select <strong>Generate source mapping</strong>. A message will display asking, "Do you want to generate the mapping from scratch?"</li>
<li>Select <strong>Yes</strong> to regenerate the mapping.</li>
</ol>
<h2 id="generate-data">Generate data</h2>
<p>You may have fields in entities that are not specified in your imported source file. In this case, you can use the auto-generated functionality in the mapping details. This makes the system generate data for a specified field. For example, let’s say you are trying to import customers and customer address information, but your <strong>Party number</strong> field is not included in the import file. You can simply toggle the <strong>Auto-generated</strong> checkbox by the field, and the system will generate a party number automatically.</p>
<p><a data-linktype="relative-path" href="media/map-details.png#lightbox"><img alt="Screenshot of the Map source to staging page showing the Mapping details view." data-linktype="relative-path" src="./rawmb500/media_map_details.png"/></a></p>
<p>However, notice that in the import project, the data source is coming from other systems, such as those legacy applications. finance and operations apps uses the business logics of each data entity, discovers the dependencies, and sequences the data entities based on their relationships and dependencies.</p>
<p>For example, if you want to import customers and customer address information, but the address information was not previously imported with the Global Address Book (GAB) entities, you can have the entity auto-generate the party number upon import and the GAB information will be created. To access this functionality, view the map of the entity, and then select the <strong>Mapping details</strong> tab. Select the fields that you want to auto-generate. This will change the source field to <strong>Auto</strong>.</p>
<p><a data-linktype="relative-path" href="media/generate-source-map.png#lightbox"><img alt="Screenshot of the Map source to staging page highlightling  the Generate source mapping button." data-linktype="relative-path" src="./rawmb500/media_generate_source_map.png"/></a></p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Using Standard and Enhanced views for tiles</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>There are two views available to work with in data management projects, the Standard and Enhanced views.</p>
<ul>
<li><strong>Standard view</strong> - Provides a streamlined interface and includes the Entity sequence button, which allows you to define the order of entity processing. This feature is crucial for ensuring dependencies between entities are properly handled during data import/export operations.</li>
<li><strong>Enhanced view</strong> - Offers additional details and controls, making it ideal for more complex projects that require fine-grained management.</li>
</ul>
<p>Both views show all available tiles in the Data management framework. However, the Enhanced view gives more detailed information and control over the project than the Standard view.</p>
<p>The following image shows the Standard view.</p>
<p><a data-linktype="relative-path" href="media/tiles-standard-view.png#lightbox"><img alt="Screenshot of the Data management tiles in the Standard view." data-linktype="relative-path" src="./rawmb500/media_tiles_standard_view.png"/></a></p>
<p>The following image shows the Enhanced view.</p>
<p><a data-linktype="relative-path" href="media/tiles-enhanced-view.png#lightbox"><img alt="Screenshot of the Data management tiles in the Enhanced view." data-linktype="relative-path" src="./rawmb500/media_tiles_enhanced_view.png"/></a></p>
<p>Prior to managing data import and export, you need to configure these tiles to successfully create, manage, and run the jobs to perform the data management activities.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Use templates in data management</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>Default templates are delivered together with each new release of finance and operations apps. Our long-term goal is to provide the templates in Lifecycle Services so that you can push them to an instance of finance and operations apps. However, for the current releases, select the <strong>Templates</strong> tile in the <strong>Data management</strong> workspace, and then select <strong>Load default templates</strong> to load the templates. To see the <strong>Load default templates</strong> menu, you must use Enhanced view.</p>
<p>We recommend using the Enhanced views to have more features and flexibility while working with your projects.</p>
<p>After the templates are loaded, you can change them to suit your business requirements. If you ever want to retrieve the original default templates, you can use the <strong>Load default templates</strong> button to add them back to your system. The templates will then be replaced with the latest versions. If you've made changes to the templates, you can make a copy of the old templates by exporting them.</p>
<p>Note that system administrator access is required to load default templates and import templates. This requirement helps guarantee that all entities are correctly loaded into the template.</p>
<p>For the newly deployed environment of finance and operations apps, the default templates are not loaded. We recommend that you select the <strong>Load default templates</strong> button to view the default templates.</p>
<p><a data-linktype="relative-path" href="media/template.png#lightbox"><img alt="Screenshot of the Load default templates button." data-linktype="relative-path" src="./rawmb500/media_template.png"/></a>
 </p>
<p>When the <strong>Load default templates</strong> dialog box appears, you can select single, multiple, or all templates to be loaded into your environment.</p>
<p><a data-linktype="relative-path" href="media/load-default-template.png#lightbox"><img alt="Screenshot of the Load default templates dialog box." data-linktype="relative-path" src="./rawmb500/media_load_default_template.png"/></a></p>
<p>Levels 10 to 22 are reserved for shared system entities so that those entities are processed first. Almost all systems also use the company-specific general ledger entities. Therefore, level 25 is reserved for those entities. These levels represent the minimum basic setup that is required for most shared data in a configuration.</p>
<p>After the basic setup is completed, many entities can be loaded in parallel across all the modules. These entities don't have to be loaded in silos by module. Instead, you can set up bands of dependencies between the data for different entities. Bands help establish execution timing between entities added to the groups because each band is defined by its execution level.</p>
<p>Entities that have no dependencies are added to band 30 in this example. Band 40 is added for entities that have a dependency on the entities in band 30. The same process is continued for bands 50 to 90, as shown in the table:</p>
<table>
<thead>
<tr>
<th>Module</th>
<th>Unit</th>
<th>Execution   Level</th>
</tr>
</thead>
<tbody>
<tr>
<td>Band 1   for dependencies</td>
<td>1</td>
<td>30</td>
</tr>
<tr>
<td>Band 2   for dependencies</td>
<td>1</td>
<td>40</td>
</tr>
<tr>
<td>Band 3   for dependencies</td>
<td>1</td>
<td>50</td>
</tr>
<tr>
<td>Band 4   for dependencies</td>
<td>1</td>
<td>60</td>
</tr>
<tr>
<td>Band 5   for dependencies</td>
<td>1</td>
<td>70</td>
</tr>
<tr>
<td>Band 6   for dependencies</td>
<td>1</td>
<td>80</td>
</tr>
<tr>
<td>Band 7   for dependencies</td>
<td>1</td>
<td>90</td>
</tr>
</tbody>
</table>
<p>After organizing the basic entities so that they can be processed in parallel, the remaining entities are organized by module, in the order that the modules should be processed in. However, many entities have many dependencies, some of which are complex.</p>
<p>For example, the Vendor posting profiles entity might require Vendors or Items entities. Although the Vendor posting profiles entity is in the Accounts payable module, it must be processed after the Product management module. In that case, if Vendors entities are 1.130.10 and Items entities are 1.300.10, the Vendor posting profiles entity must be moved so that it's after that sequence (for example, 1.310.20).</p>
<div class="NOTE">
<p>Note</p>
<p>The sequences that we have implemented are a guideline, not a requirement. There is no required relationship between a level and a module. You can rearrange the entities if the sequence doesn't work for your implementation. To add your own templates to a configuration, you can follow the preceding guidelines to help guarantee that your template is correctly merged into a project that uses default templates.</p>
</div>
<h2 id="templates-that-have-the-same-entity">Templates that have the same entity</h2>
<p>Some entities are required in more than one template. For example, you must have payment terms in both the Accounts payable and Accounts receivable templates. However, you might require only the Accounts receivable template. We added the entity to both templates for situations where you require only one of them.</p>
<p>A data project can include only one instance of an entity. If you add a template, and the template contains an entity that already exists in a data project, the entity in that template replaces the entity that is currently in the project.</p>
<p>You can use this capability to override the default templates without changing them. For example, the worker field hasn't been mapped in your data project, but you have your own template that adds workers. In this case, you can build a template that includes the entities that have the worker field. In that template, you can map the worker field. Any entities in the data project that don't have the field mapped will then be replaced.</p>
<h2 id="merged-templates">Merged templates</h2>
<p>We have created larger templates that cover multiple module areas. You can use the larger templates, or any combination of smaller templates, to build a data project. The following combined templates are available:</p>
<ul>
<li><strong>System and Shared</strong> – Include system setup, global address book, shared general ledger, and workflow.</li>
<li><strong>Financials</strong> – Includes general ledger, bank, accounts payable, tax, accounts receivable, fixed assets, and budgeting.</li>
<li><strong>Supply chain management</strong> – Includes inventory management, product management, procurement, sales and marketing, limited warehouse management, production control, and costing.</li>
<li><strong>Expense and Project Management</strong> – These templates aren't included in a larger template. However, they are designed so that they can easily be merged into a project that uses other templates.</li>
<li><strong>Workers</strong> – Includes the entities needed to add workers and re-map entities where the worker mapping was removed.</li>
</ul>
<h2 id="master-data">Master data</h2>
<p>Many default templates include entities for master data, such as customers, vendors, and released products. These entities are included to indicate the correct sequence of entities that you will require after you've loaded parameters and reference data. Master entities are most often sequenced in the module bands that are numbered 100 and above. In the grid, the entity category for these entities will be Master. If you don't want to include master data or any other entities in your configuration, remove those entities from your project.</p>
<h2 id="enable-change-tracking-for-entities">Enable change tracking for entities</h2>
<p>Change tracking enables incremental export of data from finance and operations apps by using Data management. In an incremental export, only records that have changed are exported. To enable incremental export, you must enable change tracking on entities.</p>
<p><a data-linktype="relative-path" href="media/change-tracking.png#lightbox"><img alt="Screenshot of the Change tracking button." data-linktype="relative-path" src="./rawmb500/media_change_tracking.png"/></a></p>
<p>If you don't enable change tracking on an entity, you can only enable a full export each time. For bring your own database (BYOD) use cases, change tracking can also track deletes, if the entity supports this.</p>
<p>For more information regarding BYOD, see <a data-linktype="absolute-path" href="/en-us/training/modules/prepare-data-migration-finance-operations/?azure-portal=true">Prepare data for migration to finance and operations apps</a>.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Export, import, and copy data into a legal entity</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>This unit explains how to copy data into a legal entity, and how to import and export data in finance and operations apps.</p>
<h2 id="data-import-and-export-jobs">Data import and export jobs</h2>
<p>To create and manage data import and export jobs in finance and operations apps, you can use the <strong>Data management</strong> workspace. By default, the data import and export process creates a staging table for each entity in the target database. Staging tables let you verify, clean up, or convert data before you move it.</p>
<p>The following are steps to import or export data.</p>
<ol>
<li>Create an import or export job, where you will complete the following tasks:
<ul>
<li>Define the project category.</li>
<li>Identify the entities to import or export.</li>
<li>Set the data format for the job.</li>
<li>Sequence the entities so that they are processed in logical groups and in an order that makes sense.</li>
<li>Determine whether to use staging tables.</li>
</ul>
</li>
<li>Validate that the source data and target data are mapped correctly.</li>
<li>Verify the security for your import or export job.</li>
<li>Run the import or export job.</li>
<li>Validate that the job ran as expected by reviewing the job history.</li>
<li>Clean up the staging tables.</li>
</ol>
<h2 id="create-an-import-or-export-job">Create an import or export job</h2>
<p>A data import or export job can be run one time or as many times as needed. We recommend that you take the time to select an appropriate project category for your import or export job. Project categories can help you manage related jobs.</p>
<p>When you select an entity, you must select the format of the data that will be exported or imported. You can define formats by using the <strong>Data sources</strong> setup tile. A source data format is a combination of Type, File format, Row delimiter and Column delimiter.</p>
<p>Entities can be sequenced in a data template or in import and export jobs. When you run a job that contains more than one data entity, you must make sure that they are correctly sequenced. Primarily, you sequence entities to address any functional dependencies among entities. If entities don’t have any functional dependencies, they can be scheduled for parallel import or export.</p>
<h2 id="verify-the-security-for-your-import-or-export-job">Verify the security for your import or export job</h2>
<p>Access to the <strong>Data management</strong> workspace can be restricted so that non-administrator users can access only specific data jobs. Access to a data job implies full access to the run history of that job and access to the staging tables. Therefore, you need to make sure that appropriate access controls are in place when you create a data job.</p>
<p>Use the <strong>Applicable roles</strong> menu to restrict the job to one or more security roles. Only users in those roles will have access to the job. You can also restrict a job to specific users. Securing a job by users instead of roles provides more control when multiple users are assigned to a role.</p>
<p>A job can be secured by roles, users, and legal entity at the same time. Data jobs are global in nature. Therefore, if a data job was created and used in a legal entity, the job will be visible in other legal entities in the system. This default behavior might be preferred in some application scenarios.</p>
<p>For example, an organization that imports invoices by using data entities might provide a centralized invoice processing team that is responsible for managing invoice errors for all divisions in the organization. In this scenario, it’s useful for the centralized invoice processing team to have access to invoice import jobs from all legal entities. Therefore, the default behavior meets the requirement from a legal entity perspective.</p>
<p>However, an organization might want to have invoice processing teams for each legal entity. In this case, a team in a legal entity should have access only to the invoice import job in its own legal entity. To meet this requirement, you can configure legal entity–based access control on the data jobs by using the <strong>Applicable legal entities</strong> menu inside the data job. After the configuration is done, users can view only jobs that are available in the legal entity that they are currently signed in to. To view jobs from another legal entity, users must switch to that legal entity.</p>
<h2 id="clean-up-the-staging-tables">Clean up the staging tables</h2>
<p>You can clean up staging tables by using the Staging clean up feature in the <strong>Data management</strong> workspace. You can use the following options to select which records should be deleted from which staging table:</p>
<ul>
<li><strong>Entity</strong> – If only an entity is provided, all records from that entity’s staging table are deleted. Select this option to clean up all the data for the entity across all data projects and all jobs.</li>
<li><strong>Job ID</strong> – If only a job ID is provided, all records for all entities in the selected job are deleted from the appropriate staging tables.</li>
<li><strong>Data projects</strong> – If only a data project is selected, all records for all entities and across all jobs for the selected data project are deleted.</li>
</ul>
<p>Watch this video to learn how to perform data export and import by using the <strong>Data management</strong> workspace:</p>
<div class="embeddedvideo"><iframe allowfullscreen="true" data-linktype="external" frameborder="0" src="https://learn-video.azurefd.net/vod/player?id=d3a1068e-d3ae-4896-bc10-7dce867f60c4"></iframe></div>
<h2 id="resources">Resources</h2>
<p>To learn more, see <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/data-entities/recurring-integrations/?azure-portal=true">Recurring integrations</a>.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Lab - Explore the Data management workspace</h1>
<div hidden="" id="module-unit-notification-container"></div>
<h2 id="read-this-first---before-you-start-the-lab">Read this first - before you start the lab!</h2>
<div class="IMPORTANT">
<p>Important</p>
<p>For this lab, you CAN'T sign in with your own credentials. Use the following steps to sign in to your lab environment with the correct credentials.</p>
</div>
<ol>
<li>Ensure that you're signed in to Microsoft Learn.</li>
<li>Select <strong>Launch VM mode</strong> or <strong>Sign in to launch VM mode</strong> in this unit.</li>
<li>In the <strong>Resources</strong> tab on the lab side bar, select the <strong>T</strong> icon next to <strong>Password</strong> in the <strong>Finance and Operations</strong> box, to have the administrator password for the Virtual Machine (VM) entered for you.</li>
<li>Select <strong>Enter</strong>.</li>
<li>Microsoft Edge opens. Wait for it to navigate to the <strong>Sign in</strong> page for finance and operations. If you experience an issue with the <strong>Sign in</strong> page loading, try to restart the browser in the VM.</li>
<li>On the Microsoft <strong>Sign in</strong> page in finance and operations, place your mouse cursor into the <strong>Username</strong> field.</li>
<li>On the <strong>Resources</strong> tab of the lab side bar, below the <strong>Azure portal</strong> heading, select the <strong>T</strong> icon next to <strong>Username</strong>, then press <strong>Enter</strong>.</li>
<li>Your mouse cursor is now in the <strong>Password</strong> page.</li>
<li>On the <strong>Resources</strong> tab of the lab side bar, below the <strong>Azure portal</strong> heading, select the <strong>T</strong> icon next to select <strong>Password</strong>, then press <strong>Enter</strong>.</li>
<li>In the <strong>Save password</strong> window, select <strong>Never</strong>.</li>
<li>Select <strong>Accept</strong> in the <strong>Permissions requested</strong> page.</li>
<li>To see the lab instructions, select the <strong>Instructions</strong> tab on the lab side bar.</li>
</ol>
<p>You can now begin your work on this lab.</p>
<h2 id="scenario">Scenario</h2>
<p>In this lab, you will explore some of the features in the <strong>Data management</strong> workspace in the company <strong>USMF</strong>.</p>
<ol>
<li>In company <strong>USMF</strong>, go to <strong>Workspaces &gt; Data management</strong>.</li>
<li>You will see the message <strong>Execution history was successful</strong> in the <strong>Action center</strong>.</li>
<li>Select <strong>Templates</strong> in the <strong>Data management</strong> workspace.</li>
<li>Select <strong>New</strong>, and when the new draft appears, enter <strong>035 – General Ledger Setup</strong> in the <strong>Template ID</strong> field.</li>
<li>In the <strong>Description</strong> field, enter <strong>General Ledger Setup</strong>.</li>
<li>Under the <strong>Entities</strong> field, select <strong>Add entity</strong>, and in the <strong>Entity name</strong> dropdown, select <strong>All types test entity</strong>, and then select <strong>Add entity</strong>. The entity source will also be under the <strong>Template details</strong> FastTab.</li>
<li>The <strong>Template status</strong> is currently set to <strong>Draft</strong>. To validate this new template select <strong>Validate template</strong> at the top of the page.</li>
<li>Select <strong>Save</strong> and close in the <strong>Templates</strong> page.</li>
<li>Select the  <strong>Data entities</strong> tile in the <strong>Data management</strong> workspace.</li>
<li>View available entities in finance and operations apps.</li>
<li>Select any of the entities of your choice, such as <strong>All types test entity</strong>.</li>
<li>Select <strong>Entity structure</strong> in the top menu, to see the data source. Here, you can enable or disable running business logic in your project. For instance, for data migration, you might have modified the settings of certain configurations to meet customer requirements; however, the legacy data would violate the new rule, so you might need to make the decision to turn off the rule for historical data.</li>
<li>Select <strong>Target fields</strong> in the top menu. Here you can view and edit the target fields.</li>
<li>Close the <strong>Target fields</strong> page.</li>
<li>Close the <strong>Entity structure</strong> page.</li>
<li>Select <strong>Entity model view</strong> in top menu of the <strong>Target entities</strong> page. This provides better visibility by grouping entities for each category and sub category of nodes, and by grouping the entity models.</li>
<li>In the tree on the left, expand <strong>All\SystemAdministration</strong> and select <strong>Master</strong>.</li>
<li>In the tree, expand <strong>All\SalesAndMarketing</strong> and select <strong>Document</strong> to see various entity types and entities.</li>
<li>Close the <strong>Entity model view</strong> page.</li>
<li>Select <strong>Entity category view</strong> in the <strong>Target entities</strong> page.</li>
<li>In the tree, expand <strong>All\Configuration</strong> and select <strong>SystemAdministration</strong>.</li>
<li>Close the <strong>Entity category view</strong> page.</li>
<li>Close the <strong>Target entities</strong> page.</li>
<li>Select the <strong>Data task automation</strong> tile.</li>
<li>Select <strong>Load default tasks</strong> to open the drop-down dialog.</li>
<li>From the drop-down, select a value, <strong>MS_Sample_DMFManifest</strong>.</li>
<li>Select <strong>Load</strong> and wait for the information statement that says the Manifest is loaded successfully.</li>
<li>Select <strong>Cancel</strong>.</li>
<li>Close the <strong>Data task automation</strong> page.</li>
<li>Select the <strong>Configure data source</strong> tile. Here, you can view, edit, and create data types such as CSV, Excel, and Package.</li>
</ol>
<h2 id="go-to-the-next-lab-instructions-from-the-lab-environment">Go to the next lab instructions from the lab environment</h2>
<p>Select the <strong>Next</strong> button in the bottom-right corner of the lab side bar.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Lab - Export data using the Data management workspace</h1>
<div hidden="" id="module-unit-notification-container"></div>
<h2 id="read-this-first---before-you-start-the-lab">Read this first - before you start the lab!</h2>
<div class="IMPORTANT">
<p>Important</p>
<p>For this lab, you CANNOT sign in with your own credentials.</p>
</div>
<p>If you are signed in to finance and operations in the lab environment, you don’t need to sign in again, and can begin your work on this lab.</p>
<p>If you are not signed in to the lab environment yet, then go to the first lab unit in this module for instructions. Then, after you successfully sign in, use the <strong>Next</strong> button in the <strong>Instructions</strong> tab of the lab side bar to return to this lab scenario, and begin your work.</p>
<h2 id="scenario">Scenario</h2>
<p>In this lab, you will export data from the <strong>All customers</strong> entity using the <strong>Data management</strong> workspace.</p>
<ol>
<li>In the company <strong>USMF</strong>, go to <strong>Workspaces &gt; Data management</strong>.</li>
<li>You will see the message <strong>Execution history was successful</strong> in the <strong>Action center</strong>.</li>
<li>Select <strong>Export</strong> in the <strong>Data management</strong> workspace.</li>
<li>Specify the following information on the page:
<ul>
<li><strong>Group name</strong> - Customers Export</li>
<li><strong>Description</strong> - Customer Export</li>
<li><strong>Data project operation type</strong> - Export</li>
<li><strong>Project category</strong> -  Project</li>
<li><strong>Generate data package</strong> - Yes</li>
</ul>
</li>
<li>Select <strong>Save</strong> in the Action Pane.</li>
<li>In the <strong>Selected entities</strong> FastTab, select <strong>Add entity</strong>.</li>
<li>Specify the following information in the <strong>Add entity</strong> dialog:
<ul>
<li><strong>Entity name</strong> - Select any of the Entity names from the drop-down list.</li>
<li><strong>Target data format</strong> - EXCEL</li>
<li><strong>Select fields</strong> - Importable fields</li>
</ul>
</li>
<li>Select <strong>Add</strong>. A new line will be created with the entity information you defined.</li>
<li>Review any warnings, and then select <strong>Close</strong>.</li>
<li>Select the entity line, and then select <strong>Export</strong> in the Action Pane. The data job will run.</li>
<li>When the <strong>Batch job is scheduled</strong> dialog box appears. select <strong>Close</strong>.</li>
<li>Select <strong>Refresh</strong> when the job is complete (if the <strong>Refresh</strong> button is not displayed return to the previous page by using <strong>Click to go back</strong> on the browser page, and again select <strong>Export</strong>. Now the <strong>Refresh</strong> button will appear on the <strong>Execution summary</strong> page). You will receive a notification that the export is completed.</li>
<li>Select <strong>Download package</strong> in the Action Pane. A .zip file will download.</li>
<li>Open the .zip file and then open the Excel file that is in the .zip file.</li>
<li>Here you will see all the data that exported from finance and operations.</li>
</ol>
<h2 id="close-the-lab-environment">Close the lab environment</h2>
<ol>
<li>Select <strong>Done</strong> in the <strong>Instructions</strong> pane in the lab side bar.</li>
<li>In the <strong>Lab is complete</strong> window, select <strong>Continue</strong>, and then select <strong>Leave</strong> to return to the next unit in the module.</li>
</ol>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Database movement operations</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>Database movement operations are a suite of self-service actions that you can use as part of Data Application Lifecycle Management (also referred to as DataALM). These actions provide structured processes for common implementation scenarios such as golden configuration promotion, debugging/diagnostics, destructive testing, and general refresh for training purposes.</p>
<div class="mx-imgBorder">
<p><img alt="Diagram of the Create request for database movement operation page in Lifecycle Services." data-linktype="relative-path" src="./rawmb500/media_request_database_movement.png"/></p>
</div>
<p>With database movement operations, you can:</p>
<ul>
<li>Run database movement operation from and to Tier-2+ environments directly in Microsoft Dynamics Lifecycle Services.</li>
<li>Create requests for database operations for production environment in Lifecycle Services.</li>
</ul>
<h2 id="refresh-database">Refresh database</h2>
<p>You can use Lifecycle Services to perform a refresh of the database to a sandbox user acceptance testing (UAT) environment. A database refresh lets you copy the transactional and financial reporting databases of your production environment into the target, sandbox UAT environment. If you have another sandbox environment, you can also copy the databases from that environment to your target, sandbox UAT environment.</p>
<div class="NOTE">
<p>Note</p>
<p>Copying production data to your sandbox environment for the purpose of production reporting is not supported.</p>
</div>
<h2 id="export-database">Export database</h2>
<p>You can use Lifecycle Services to export a database from a sandbox user acceptance testing (UAT) environment to the Asset library. The environment will be unavailable for other servicing operations, such as Sandbox refresh or package deployment during this time. The source environment will be usable from a Dynamics user perspective.</p>
<h2 id="import-database">Import database</h2>
<p>You can import a database that is prepared from a developer environment to a standard user acceptance test (UAT), or a database previously exported from a UAT environment.</p>
<h2 id="point-in-time-restore">Point-in-time restore</h2>
<p>You can use Lifecycle Services to perform the point-in-time restore (PITR) for a sandbox user acceptance testing (UAT) environment. Microsoft maintains <a data-linktype="absolute-path" href="/en-us/azure/azure-sql/database/automated-backups-overview?tabs=single-database/?azure-portal=true">automated backups</a> of the business and financial reporting databases for 28 days for Production environments and 14 days for Sandbox environments.</p>
<h2 id="point-in-time-restore-of-the-production-database-to-a-sandbox">Point-in-time restore of the production database to a sandbox</h2>
<p>You can use Lifecycle Services to do a point-in-time restore (PITR) of the production database to a user acceptance testing (UAT) sandbox environment. To provide customers with data application lifecycle management (DataALM) capabilities that do not rely on human or manual processes, the Lifecycle Services team has introduced an automated refresh database actions for this purpose.</p>
<h2 id="database-operations-between-tier-1-and-tier-2">Database operations between Tier-1 and Tier-2+</h2>
<p>You can use the following options to move databases between Tier-1 and Tier-2 customer/partner managed environments:</p>
<ul>
<li>Bacpac procedure: from SQL Server to Azure SQL or from Azure SQL to SQL Server</li>
<li>SQL Server backup/restore between one-box environments (SQL Server)</li>
</ul>
<div class="mx-imgBorder">
<p><img alt="Diagram of the Tier-1 and Tier-2 environments." data-linktype="relative-path" src="./rawmb500/media_tier_1_tier_2_database_operations.png"/></p>
</div>
<p>See <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/database/dbmovement-operations/?azure-portal=true">Database movement operations home page</a> to learn more about database movement operations</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Data sharing framework</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>Cross-company data sharing lets you replicate (share) reference and group data among companies. Data integrity is verified before replication occurs.</p>
<p>Examples of cross-company data sharing and the basic logic:</p>
<ul>
<li>The same payment terms and payment day definitions are used across fifteen legal entities.</li>
<li>The same terms of delivery are used across seven legal entities in three countries/regions.</li>
<li>Records created, updated, and deleted in any of the companies within the policy will be replicated immediately, across all the companies.</li>
<li>Fields that are not selected for sharing are maintained in each company and will not trigger any replication.</li>
<li>As part of enabling a policy, it is optional to copy any existing records.</li>
</ul>
<h2 id="cross-company-sharing-framework-important-aspects">Cross-company sharing framework important aspects</h2>
<p>The following aspects need to be considered before using cross-company data sharing.</p>
<ul>
<li>Use to replicate (share) reference, parameter, and group data between companies within an environment.</li>
<li>Cannot be used for transactional data between companies.</li>
<li>Data integrity must be verified before replication.</li>
<li>Data sharing policy should be enabled after importing data in seeding company.</li>
<li>Apply to production only after testing and validation sandbox environment.</li>
<li>Data sharing policy can be updated or disabled.</li>
<li>Cannot be used with dual write.</li>
<li>Examples of cross-company shared data includes customers and vendors.</li>
</ul>
<h2 id="when-to-use-cross-company-data-sharing-feature">When to use cross-company data sharing feature?</h2>
<p>Use cross-company data sharing for the following business scenarios:</p>
<ul>
<li>Sharing of simple reference and group data in a single deployment.</li>
<li>Sharing among companies that have similar configurations.</li>
<li>Sharing scenarios that have been explicitly evaluated by Microsoft.</li>
</ul>
<p>Cross-company data sharing is not supported for the following scenarios:</p>
<ul>
<li>Franchising solutions, where thousands of records are shared across thousands of companies.</li>
<li>Sharing of transactional records for reporting or management purposes, such as consolidations.</li>
<li>Sharing across deployments.</li>
<li>Complex scenarios, such as replication of subtype/supertype tables or tables that have date effectivity rules.</li>
<li>Tables that do not have a unique index.</li>
</ul>
<h2 id="other-tools-for-data-management">Other tools for data management</h2>
<p>Other tools for data management are:</p>
<ul>
<li><strong>Bring your own database (BYOD)</strong> – Export entities to your own database.</li>
<li><strong>Entity store refresh</strong> – For embedded Power BI reports.</li>
<li><strong>Process data package</strong> –  A wizard functionality that consolidates multiple data packages in one bundle.</li>
<li><strong>Data validation checklist workspace</strong> –To track data validation processes across companies, areas, and people.</li>
<li><strong>Office add-in</strong> – Export and import data via Excel add-in using data entities.</li>
</ul>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Check your knowledge</h1>
<div hidden="" id="module-unit-notification-container"></div>
<h2>Answer the following questions to see what you learned</h2>
<form aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>Which one of the following data management concepts contains a data project manifest and data files?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Data entities</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Data project</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Data package</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>In which one of the following data management frameworks can you perform asynchronous integration by using data entities?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Data migration</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Set up and copy configurations</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Integration</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>Which activity is performed using data entities?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Pushing data from source to central storage</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Pushing data from central storage to staging</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Pushing data from staging to target</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-4" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-4">
<span class="font-weight-semibold">4.</span>
<p>For the import or export operation, users need to configure the entities that are being imported, define the default processing options, and define the mapping definition. Where are these operations performed?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-0">
<input class="radio-dot choice-input" id="quiz-choice-3-0" name="3" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Data Projects</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-1">
<input class="radio-dot choice-input" id="quiz-choice-3-1" name="3" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Data Jobs</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-2">
<input class="radio-dot choice-input" id="quiz-choice-3-2" name="3" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Job History</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-3">
<input class="radio-dot choice-input" id="quiz-choice-3-3" name="3" type="radio" value="3"/>
<div class="margin-inline-sm radio-label-text">
<p>Data Packages</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-5" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-5">
<span class="font-weight-semibold">5.</span>
<p>You need to allow access to your Customer records outside of finance and operations apps to be exposed in a Power App. Which of the following must be set up to make that work?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-0">
<input class="radio-dot choice-input" id="quiz-choice-4-0" name="4" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Data job</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-1">
<input class="radio-dot choice-input" id="quiz-choice-4-1" name="4" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Data project</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-4-2">
<input class="radio-dot choice-input" id="quiz-choice-4-2" name="4" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Data entity</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>In this module, you have learned about the basic concepts of the Data management platform in finance and operations apps, and examined integration scenarios that used data entities.</p>
<p>Additionally, you were able to observe how easy it was to use data management functionality to perform complex tasks of data migration, such as import and export data. This module also showed you how to benefit from data import and export jobs, and then clean up the staging tables prior to each new project run as a best practice.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>To test and evaluate the customer solution prior to go-live, you
need to have an environment of finance and operations apps,
with all the configurations and possible customizations through
extensions.</p>
<p>It is always beneficial to have a methodology to ensure that creation and
testing is organized and planned properly for short, efficient, and
role-focused test case scenarios.</p>
<p>To validate the solution that might have been customized by extensions, or
when you are identifying possible issues with functionality of finance and operations apps
that were caused by wrong configuration, you need to create test cases. Test cases
can help you, as a functional consultant, and users to approve
the user acceptance documents.</p>
<p>You can use the task recorder and business process modeler (BPM) to
create user acceptance test libraries. The task recorder is a powerful
tool to record test cases, and you can organize them by business processes
by using BPM.</p>
<p>You can use BPM to distribute test libraries to your customers through
Lifecycle Services and Lifecycle Services solutions. You can also use
BPM to write and distribute test libraries across different projects
and teams.</p>
<p>Because BPM can be synchronized with Azure DevOps (formerly known as
Visual Studio Team Services), test cases are automatically created
(including test steps) in your Azure DevOps project.</p>
<p>Azure DevOps can then serve as your test configuration and test
management tool where you can create targeted test plans and test
suites, manage the running of tests, and investigate results.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Create user acceptance test libraries</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>The business process modeler (BPM) is a Lifecycle Services tool to describe a
hierarchy of business processes and user tasks. Lifecycle Services also allows
Microsoft partners and customers to write and distribute BPM libraries
across Lifecycle Services projects by means of the Asset library.</p>
<h3 id="create-a-bpm-library">Create a BPM library</h3>
<p>You can browse a BPM library that is a global library or a corporate
library. However, before you can edit and work with a BPM library, it
must be part of your Lifecycle Services project. Libraries that are distributed by
Microsoft appear under <strong>Global libraries</strong>, whereas libraries that are
published by your organization appear under <strong>Corporate libraries</strong>.</p>
<p>Note that BPM localization is not supported. If you edit in the BPM
client in any language other than US English, your changes will only
display when you view the BPM in the language in which the changes were
made. To view any changes that were made in US English, you must synchronize with
Visual Studio Team Server before the changes will display.</p>
<p>You can create a BPM library in several ways.</p>
<p>To create a library, you need to sign in to Lifecycle Services, select the <strong>Business
process modeler</strong> tile, or select it from the LCS menu. Then create a new library.</p>
<p><img alt="Screenshot of the Business process modeler tile." data-linktype="relative-path" src="./rawmb500/media_bpm_1.png"/></p>
<p>The library can also be created by using the Microsoft Excel import functionality.</p>
<p><a data-linktype="relative-path" href="media/bpm-import-excel.png#lightbox"><img alt="Screenshot of the Microsoft Excel import button." data-linktype="relative-path" src="./rawmb500/media_bpm_import_excel.png"/></a></p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Record test cases and save to the business process modeler (BPM)</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>After you have created a BPM library, you'll need to use the task
recorder to create your test cases and then upload the cases to BPM.
There are several ways to do this.</p>
<p>If you're using a BPM library that already has all the necessary task
recordings (test cases) attached, you can skip this step. Otherwise,
follow the subsequent instructions to create new task recordings.</p>
<p>To enable the effective running of your tests by using automation tools,
make sure that all your task recordings start on the main dashboard of
finance and operations apps.</p>
<p>For end-to-end processes that are performed by more than one user, we
recommend that you divide your task recordings into user-specific tasks.
This simplifies the maintenance of test cases and allows you to run
test cases in the context of security roles, which is a best practice.</p>
<p>Watch this video for a demonstration of how to use the task recorder to create a test case for the Regression suite automation tool (RSAT).</p>
<div class="embeddedvideo"><iframe allowfullscreen="true" data-linktype="external" frameborder="0" src="https://learn-video.azurefd.net/vod/player?id=3e1fd568-558a-4647-ae6e-6efc3f4602fc"></iframe></div>
<h3 id="create-and-save-a-new-task-recording">Create and save a new task recording</h3>
<ol>
<li><p>Go to <strong>Settings &gt; Task recorder</strong>.</p>
<p><img alt="Screenshot of the Task recorder option in the settings menu." data-linktype="relative-path" src="./rawmb500/media_task_recorder.png"/></p>
</li>
<li><p>Select <strong>Create recording</strong>.</p>
<p><img alt="Screenshot of the Create recording in the task recorder menu." data-linktype="relative-path" src="./rawmb500/media_create_new_recording.png"/></p>
</li>
<li><p>Enter a name for the recording and then select <strong>Start</strong>.</p>
<p><img alt="Screenshot of the Start page with name and description fields." data-linktype="relative-path" src="./rawmb500/media_start_1.png"/></p>
</li>
<li><p>When the recording is complete, in the Task recorder pane, select
<strong>Stop</strong>.</p>
</li>
<li><p>To save the task recording to an attached BPM, select <strong>Save to Lifecycle Services</strong>.</p>
<p><img alt="Screenshot of the Save to Lifecycle Services feature." data-linktype="relative-path" src="./rawmb500/media_lcs_1.png"/></p>
</li>
<li><p>Select the library that you want to save the recording to and then select <strong>OK</strong>. This automatically saves the recording into Lifecycle Services. If you already have a business library, then identify that in <strong>System administration &gt; Setup &gt; System Parameters &gt; Help</strong> tab.</p>
</li>
<li><p>If you also want to save the recording on your computer, select <strong>Save to this PC</strong>. The extension of the recording file is AXTR.</p>
</li>
</ol>
<h3 id="upload-an-axtr-file-to-bpm">Upload an AXTR file to BPM</h3>
<p>If you have saved your recordings (AXTR files) to your PC, follow these
steps to upload them to BPM.</p>
<ol>
<li><p>In Lifecycle Services, in your project, on the <strong>Business process libraries</strong> page, select the library to upload the task recording to.</p>
</li>
<li><p>In the right pane, select <strong>Upload</strong>.</p>
</li>
<li><p>Select <strong>Browse</strong> to find and select the file to upload, and then  select <strong>Upload</strong>.</p>
</li>
</ol>
<h3 id="download-a-task-recording">Download a task recording</h3>
<p>You can download a task recording (AXTR file) that has been uploaded to a BPM process.</p>
<ol>
<li>In Lifecycle Services, in your project, on the <strong>Business process libraries</strong> page, select the library to download the task recording.</li>
<li>Select a process that has task recording uploaded.</li>
<li>On the <strong>Overview</strong> pane, select <strong>Download</strong> to save the task recording (AXTR).</li>
</ol>
<h3 id="save-an-existing-task-recording-to-bpm">Save an existing task recording to BPM</h3>
<ol>
<li><p>To attach an existing task recording, sign in to the client.</p>
</li>
<li><p>Go to <strong>Settings &gt; Task recorder</strong>.</p>
</li>
<li><p>Select <strong>Edit Recording</strong> and attach the file by either saving directly to Lifecycle Services or downloading the AXTR and then uploading to BPM.</p>
<p><img alt="Screenshot of the Edit recording feature." data-linktype="relative-path" src="./rawmb500/media_edit_recording.png"/></p>
</li>
</ol>
<h3 id="guidelines-for-recording-test-cases">Guidelines for recording test cases</h3>
<p>Follow these guidelines when writing and recording your test cases,
especially if you are planning to automate a test run. The process
and tools that are described in this article apply to business process acceptance
tests; they are not meant to replace component and unit testing that is
typically owned by developers.</p>
<ul>
<li><p>Write a limited number of test cases that, when combined, cover complete end-to-end processes.</p>
</li>
<li><p>Focus on business processes that have been customized.</p>
</li>
<li><p>An individual test case (recording) should cover one or two business tasks only, typically run by one person. This simplifies task recording maintenance. Do not combine a complete end-to-end business process, such as procure-to-pay or order-to-cash, into one large task recording.</p>
<ul>
<li>For example, instead of having <strong>RFQ &gt; Purchase Order &gt; Product Receipt &gt; Vendor Invoice &gt; Vendor Payment</strong> as one test case, divide the process into three or four test cases. You will have the opportunity to combine these tests into an ordered test suite later.</li>
</ul>
</li>
<li><p>A test case should have at least one validation. Try to validate critical fields that cover the impact of other fields.</p>
<ul>
<li>For example, validation of totals on sales or purchase orders cover the unit price/quantity/discount/tax.</li>
</ul>
</li>
<li><p>Avoid printing a report in a test case. If a test case needs to print a report, it should be selected on screen.</p>
</li>
<li><p>80+ percent of test cases should be of transactions or source documents. Master data should be limited to up to 20 percent of test cases only.</p>
</li>
</ul>
<h2 id="regression-suite-automation-rsat-tool">Regression suite automation (RSAT) tool</h2>
<p>To learn more about how to set up and use the Regression suite automation (RSAT) tool, review the <a data-linktype="absolute-path" href="/en-us/training/modules/use-regression-suite-automation-tool-rsat/?azure-portal=true"><strong>Use RSAT with Dynamics 365 Commerce</strong></a> training module. The content applies to other finance and operations apps than Dynamics 365 Commerce.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Synchronize and configure your test plan in Azure DevOps</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>An acceptance test library is your starting point. It typically contains
all test cases (task recordings) of an application that is organized by business
processes.</p>
<p>During a test pass, you usually do not need to run all test cases. The
test cases that you select depend on the phase of your implementation or the
nature of the update that you are planning to apply to your production
environment.</p>
<p>Azure DevOps enables you to organize your test cases in test plans and
test suites. A test plan contains one or more test suites (a subset of
your test library). Test cases can belong to more than one test suite.</p>
<p>When you have selected your acceptance testing BPM library, synchronize
it with Azure DevOps and create your test plan and test suites.</p>
<h3 id="sync-with-azure-devops">Sync with Azure DevOps</h3>
<p>Synchronize your BPM library with your Azure DevOps project. For more
information, see <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/lifecycle-services/synchronize-bpm-vsts?azure-portal=true#synchronize-a-bpm-library-with-a-azure-devops-project">Synchronize a BPM library with an Azure DevOps project</a>.</p>
<p>After configuration is complete, you can synchronize the BPM library with an
Azure DevOps project.</p>
<ol>
<li><p>On the <strong>Business process libraries</strong> page, on the tile for the library that you want to synchronize, select the ellipsis button (...) and then select <strong>Azure DevOps sync</strong> (VSTS sync). You can also start Azure DevOps synchronization from the toolbar in a BPM library. Select the ellipsis button (...) and then select <strong>Azure DevOps sync</strong>.</p>
</li>
<li><p>After Azure DevOps synchronization is complete, select the ellipsis  button (...) and then select <strong>Sync test cases</strong>. When this step is complete, your task recordings will become test cases in Azure DevOps and a link will appear under the <strong>Requirements</strong> tab.</p>
</li>
</ol>
<p><a data-linktype="relative-path" href="media/sync-test-cases.png#lightbox"><img alt="Screenshot showing the Sync test cases." data-linktype="relative-path" src="./rawmb500/media_sync_test_cases.png"/></a></p>
<p>In addition to the test steps, the task recording XML file is attached
to the Azure DevOps test case. This file will be needed if you want to
automate test runs.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Run user acceptance tests</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>To run your user acceptance tests, you will need to create a test plan and test suite in
Azure DevOps. This will allow you to run an ordered suite of test cases
and easily manage, investigate, and track the results.</p>
<ol>
<li><p>Sign in to Azure DevOps and select the project and test plan that you want to test in.</p>
</li>
<li><p>On the toolbar, select <strong>Test &gt; Test Plans</strong>.</p>
</li>
<li><p>On the left pane, select the drop-down next to the green plus <strong>+</strong> sign and then select <strong>Static suite</strong>.</p>
</li>
<li><p>Enter a name for the suite.</p>
</li>
<li><p>Select <strong>Add existing</strong> and query the tag <strong>Lifecycle Services:Test Cases</strong>.</p>
</li>
<li><p>Select <strong>Run &gt; Add test cases</strong>.</p>
</li>
<li><p>Select the test case to view details and the attached XML file.</p>
</li>
</ol>
<p>Create various test suites under the same test plan and then
use custom queries to add specific test cases to a test suite. A test
case can belong to more than one test suite.</p>
<h3 id="run-manual-test-cases">Run manual test cases</h3>
<p>When you have a test suite, you are ready to use it for regression
testing after updates have been made to your finance and operations apps
application in a sandbox or test environment. You can run the test cases
in your test suite manually. Alternatively, you can play the task recordings that are part of
the test suite and use Azure DevOps to denote the test cases as passed or failed.</p>
<p><img alt="Screenshot of the manual tests outcome field." data-linktype="relative-path" src="./rawmb500/media_manual_tests.png"/></p>
<p>Azure DevOps also provides a tool, named Test Runner, to manage manual
test case runs. For more information about using Test Runner,
see <a data-linktype="absolute-path" href="/en-us/azure/devops/test/run-manual-tests?azure-portal=true">Run manual tests</a>.</p>
<p>We recommend that you take advantage of Azure DevOps because it provides a
rich set of management features that are not only for testing but also for result
management and mitigation.</p>
<h3 id="run-automated-test-cases">Run automated test cases</h3>
<p>The Dynamics 365 Unified Operations platform provides developers with
tools to write test cases based on task recordings and use Azure DevOps
to manage the automated running of these test cases.</p>
<p>Developers can use the build and test automation capabilities of build
and test environments. For more information, see <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/dev-tools/continuous-delivery-home-page/?azure-portal=true">Continuous delivery home page</a>.</p>
<p>The Regression Suite Automation Tool (RSAT)significantly reduces the time and cost of user acceptance testing (UAT). RSAT lets functional power users record business tasks by using Task recorder and then convert the recordings into a suite of automated tests, without having to write source code. RSAT is fully integrated with Microsoft Azure DevOps for test execution, reporting, and investigation. Test parameters are decoupled from test steps and stored in Microsoft Excel files.</p>
<p>Download the tool and user manual from <a data-linktype="external" href="https://www.microsoft.com/download/details.aspx?id=57357">finance and operations apps, Regression Suite Automation Tool</a>.</p>
<h4 id="trial-without-azure-devops-license">Trial without Azure DevOps license</h4>
<p>If your organization currently does not have a subscription to the Azure DevOps Test plan user license, there are still options for running a trial of the RSAT tool without the connection to Azure DevOps. This will allow you to gain insight and personally experience the test automation abilities of RSAT before fully committing to the subscription in Azure DevOps.</p>
<p>With the ability to run RSAT on a trial basis without a subscription to Azure DevOps, a user can manually upload the task recordings they have made into RSAT. Since this a trial, only the user who is uploading the task recordings will have the ability to run the test automations through the tool. Running the trial will enable the user to see the benefits of the tool for their organization before a commitment to an Azure DevOps subscription. For full access and to be able to run RSAT as normal along with the connection to Azure DevOps.</p>
<p>For information about purchasing a license, see <a data-linktype="external" href="https://azure.microsoft.com/pricing/details/devops/azure-devops-services">Pricing for Azure</a>.</p>
<p>To see how to create a test plan in Azure DevOps to use with RSAT, watch this video.</p>
<div class="embeddedvideo"><iframe allowfullscreen="true" data-linktype="external" frameborder="0" src="https://learn-video.azurefd.net/vod/player?id=5313ebe6-9e73-4a6d-9abe-67b616bcb555"></iframe></div>
<p>To see how to use RSAT, watch this video:</p>
<div class="embeddedvideo"><iframe allowfullscreen="true" data-linktype="external" frameborder="0" src="https://learn-video.azurefd.net/vod/player?id=88daf54a-0b81-4069-89fd-ac528d66543d"></iframe></div>
<h3 id="rsat-supports-parallel-execution">RSAT supports parallel execution</h3>
<p>One of the benefits that RSAT tool provides is that a user can run multiple instances of RSAT on the same environment. This saves both time and money since multiple environments are not required to run test scripts, but instead they can be parallelly executed. An example of this in practice may include one user running a fairly large number of test cases at the same time, instead of having to run them sequentially. Another user would also be able to work out of the same environment and run separate test cases, to maximize environment resources.</p>
<p>There's an option to configure how many concurrent instances the environment can process concurrently. The option can optimize use of environment resources.</p>
<p>This feature can also be used when executing tests from Azure DevOps pipelines, by running multiple pipelines scheduled to run at the same time. This way, multiple test runs can execute in parallel on one environment to help process all tests faster.</p>
<h3 id="investigate-test-runs">Investigate test runs</h3>
<p>When an automated run is complete, on the Azure DevOps toolbar, select <strong>Test &gt; Runs</strong> (or <strong>Test Plans &gt; Runs</strong>) to investigate your test run. Select the desired test run to investigate test case failures
and errors.</p>
<p>You can also go to your test suite in Azure DevOps to see the latest results that are associated with your test cases.</p>
<p>For more information on testing and test management in Azure DevOps, see <a data-linktype="absolute-path" href="/en-us/azure/devops/?azure-portal=true">Azure DevOps documentation</a>.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Data task automation</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>Data task automation in finance and operations apps lets you repeat many
types of data tasks and validate the outcome of each task. Data task
automation is useful for projects that are in the implementation phase.</p>
<p>For example, you can automate the creation and configuration of data
projects. You can also configure and activate the running of
import/export operations, such as the setup of demo data, golden
configuration data, and other tasks that are related to data migration.
You can also create automated testing of data entities by using task
outcome validation.</p>
<p>We recommend the following approach for data task automation:</p>
<ol>
<li><p><strong>Identify the data-related tasks that will benefit from
automation</strong> - Implementation teams should review their
configuration management plan and data migration plan to identify
potential data tasks for automation and also to identify data
entity test cases.</p>
</li>
<li><p><strong>Define tasks</strong> - Tasks are defined in an XML manifest. You can
keep your manifest under source control as part of configuration
management in your application lifecycle management (ALM) strategy.</p>
</li>
<li><p><strong>Put the data packages that are related to data task automation in
the Shared asset library of Lifecycle Services</strong> - You can also use a specific Lifecycle Services
project as you require. The Data task automation manager can consume
packages from any sandbox and/or production environment that is
related to the Lifecycle Services project.</p>
<div class="NOTE">
<p>Note</p>
<p>The user account that runs Data task automation manager in finance and operations apps must have access to Lifecycle Services and to the Lifecycle Services project that is referenced in the manifest for data packages.</p>
<p>Although data task automation can be run in any environment in the cloud, we recommend that you not run any import/export tasks that use integration application programming interfaces (APIs) in a production environment. Data task automation that involves integration APIs should be used only for automated testing.</p>
</div>
</li>
<li><p><strong>Run the data tasks and then review the outcomes</strong> - Data task
automation manager provides the success or failure outcome for each
task. It also provides insights into the reason why a task failed.</p>
</li>
</ol>
<p>For more information, refer to <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/data-entities/data-task-automation/?azure-portal=true">Data task automation</a>.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Exercise - Build test scripts to test business functionality</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>After you have created a Business Process Modeler (BPM) library, you'll need to use Task recorder
to create your test cases and then upload the cases to BPM.</p>
<p>Next, you will need to create a test plan and test suite in Azure
DevOps. This will allow you to run an ordered suite of test cases
and easily manage, investigate, and track the results.</p>
<h3 id="before-you-begin">Before you begin</h3>
<p>To get the most benefit from this exercise, we recommend that you have
the standard sample data available in finance and operations apps installed by using Lifecycle Services.</p>
<h3 id="create-a-bpm-library">Create a BPM library</h3>
<ol>
<li>In Lifecycle Services, navigate to your project. In the tiles on the right, select <strong>Business process modeler</strong>.</li>
<li>On the <strong>Business process libraries</strong> page, select <strong>New library</strong>.</li>
<li>Enter a name. for example <strong>Training First</strong> for the new library, and then select <strong>Create</strong>. </li>
</ol>
<h3 id="add-a-new-process">Add a new process</h3>
<ol>
<li>In the BPM library, select <strong>Training First</strong>.</li>
<li>Highlight the process <strong>Sample Core Business Process</strong> and then select <strong>Add process</strong>.</li>
<li>You can select to add the process as a child or a sibling of the selected process node. In this way, you can create a semantic hierarchy of business processes. Select <strong>As child</strong>.</li>
</ol>
<h3 id="edit-the-properties-of-the-process">Edit the properties of the process</h3>
<ol>
<li>In the BPM library, select the process node to edit <strong>New business process</strong>.</li>
<li>On the right-pane, on the <strong>Overview</strong> tab, select <strong>Edit mode</strong>.</li>
<li>Enter a name and description for the process node:
<ul>
<li><strong>Name</strong>: Create a sales order</li>
<li><strong>Description</strong>: This process documents the creation of a sales order.</li>
</ul>
</li>
<li>Optionally, select the industries and the countries or regions that the process applies to. You can also add keywords and links. Keywords let you define categories, work streams, or other metadata. Links (URLs) let you reference external sites or documentation.</li>
<li>When you've finished editing the properties, select <strong>Save</strong>.</li>
</ol>
<h3 id="copy-a-library">Copy a library</h3>
<p>You may have the need to copy a library, for example, for a variation. This task illustrates how it’s done.</p>
<ol>
<li><p>Open the <strong>Business process libraries</strong> page via the <strong>Business process modeler</strong> tile on the project page on Lifecycle Services.</p>
</li>
<li><p>On the tile for <strong>Training first</strong>, as the library that you want to copy, select the ellipsis button (...) and then select <strong>Copy</strong>. </p>
</li>
<li><p>Enter a name for the library <strong>Training Second</strong> and then select <strong>Create</strong>. </p>
</li>
</ol>
<h3 id="add-a-new-child-process">Add a new child process</h3>
<ol>
<li>In the <strong>Training Second</strong> library, select the existing process <strong>Create a sales order</strong>. You do this by selecting the caret next to <strong>Sample Core Business Process</strong> and highlighting the <strong>Create a sales order</strong> line.</li>
<li>Select <strong>Add process</strong>. You can select to add the process as a child or a sibling of the selected process node. In this way, you can create a semantic hierarchy of business processes. Select <strong>As child</strong>.</li>
</ol>
<h3 id="edit-the-properties-of-the-process-1">Edit the properties of the process</h3>
<ol>
<li>On the right-pane, on the <strong>Overview</strong> tab, select <strong>Edit</strong> mode.</li>
<li>Enter a name and description for the process node:
<ul>
<li><strong>Name</strong>: Create a sales line</li>
<li><strong>Description</strong>: This process creates a line for the parent sales order.</li>
</ul>
</li>
<li>When you've finished editing the properties, select <strong>Save</strong>.</li>
</ol>
<h3 id="record-test-cases-and-save-to-bpm">Record test cases and save to BPM</h3>
<ol>
<li><p>Open the finance and operations apps client and sign in.</p>
</li>
<li><p>Select the company that you want to use while recording, in this case <strong>USMF</strong>.</p>
</li>
<li><p>Go to <strong>Settings &gt; Task recorder</strong>.</p>
<blockquote>
<p><img alt="Screenshot of the Task recorder feature in the Settings menu." data-linktype="relative-path" src="./rawmb500/media_task_recorder.png"/></p>
</blockquote>
</li>
<li><p>Select <strong>Create a new recording</strong>.</p>
</li>
<li><p>Enter a name for the recording: <strong>Sales order creation</strong>, and then select <strong>Start</strong>. Recording
begins the moment that you select <strong>Start</strong>.</p>
</li>
<li><p>Navigate to <strong>Modules &gt; Accounts receivable &gt; Orders &gt; All sales orders</strong>.</p>
</li>
<li><p>Click <strong>New</strong>.</p>
</li>
<li><p>Enter <strong>US-001</strong> in the <strong>Customer</strong> field.</p>
</li>
<li><p>Select <strong>OK</strong>.</p>
</li>
<li><p>In the sales order line, enter <strong>A0001</strong> in the <strong>Item</strong> field.</p>
</li>
<li><p>In the <strong>Site</strong> field, enter <em>1</em>.</p>
</li>
<li><p>Allow the remaining values to default.</p>
</li>
<li><p>Select <strong>Save</strong>, and close with the <strong>X</strong> button.</p>
</li>
<li><p>When the task is complete, on the Task recorder pane,
select <strong>Stop</strong>.</p>
</li>
<li><p>To save the task recording to an attached BPM, select <strong>Save to
Lifecycle Services</strong>.</p>
<ul>
<li>If you haven’t connected to Lifecycle Services yet, now is the time to establish a connection. Select the <strong>Click here to connect to Lifecycle Services</strong> button.</li>
<li>You should be sent to a browser tab saying that you were successful. You can close the tab.</li>
<li>Return to your finance and operations screen and select <strong>OK</strong>.</li>
</ul>
</li>
<li><p>Select the library that you want to save the recording to, which will have the name <strong>Training Second</strong>, and the process <strong>Create a sales order</strong>, then select <strong>OK</strong>.</p>
</li>
</ol>
<h3 id="alternate-method--save-locally-then-upload">Alternate method – save locally, then upload</h3>
<ol>
<li><p>Alternatively, you can select <strong>Save to this PC</strong>. Complete the save process of the .axtr.</p>
</li>
<li><p>Open or return to Lifecycle Services, in your project, on the <strong>Business process libraries</strong> page, select the library to upload the task recording to.</p>
</li>
<li><p>Locate and select the process (<strong>Create a sales order</strong> under <strong>Training Second</strong>) to upload the task recording to.</p>
</li>
<li><p>On the right-pane, select <strong>Upload</strong>.</p>
</li>
<li><p>Select <strong>Browse</strong> to find and select the .axtr file to upload, and then select <strong>Upload</strong>.</p>
</li>
</ol>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Check your knowledge</h1>
<div hidden="" id="module-unit-notification-container"></div>
<h2>Answer the following questions to see what you learned</h2>
<form aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>Manage and distribute BPM libraries is part of which phase of the user acceptance tests processes in finance and operations apps?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Create user acceptance test library</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Synchronize and configure your test cases in Azure DevOps</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Run your tests</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>Which one of the following considerations is part of the guidelines for recording test cases in finance and operations apps when you create a test case (recording)?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>A test case (recording) should cover one or two business tasks only and is typically performed by one person.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>A test case (recording) should cover all business tasks and is typically performed by one person.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>A test case (recording) should cover all business tasks and is typically performed by multiple roles and different personnel.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>Which one of the following considerations is part of the guidelines when you create test cases and work with transactions and source documents?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>80+ percent of test cases should be from transactions or source documents. Master data should be limited to up to 20 percent of test cases.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>80+ percent of test cases should be Master data. Twenty percent of test cases should be from transactions or source documents.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>100 percent of test cases should be from transactions or source documents.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-4" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-4">
<span class="font-weight-semibold">4.</span>
<p>When you run data task automation, which one of the following access controls rights?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-0">
<input class="radio-dot choice-input" id="quiz-choice-3-0" name="3" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Access to Lifecycle Services and to the Lifecycle Services project that is referenced in the manifest for data packages</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-1">
<input class="radio-dot choice-input" id="quiz-choice-3-1" name="3" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Access to the Lifecycle Services project</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-3-2">
<input class="radio-dot choice-input" id="quiz-choice-3-2" name="3" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Access to Lifecycle Services data packages and asset libraries</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>In this module, you learned how to build test cases to test business
functionality without the need for development skills.</p>
<p>The main purpose of user acceptance testing (UAT) is to verify that
specific business scenarios work as you would expect.</p>
<p>The goal is to help you catch issues or errors before you go
to the production environment without needing a developer to code for you.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Introduction</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>All your hard work becomes a success by moving the implemented solution in finance and operations apps to the production environment, which is the final stage of completing an implementation.</p>
<p>You want a happy customer, a quality solution, and peace of mind during this important phase, which is known as go-live.</p>
<p>It is important to prepare for the go-live phase of finance and operations apps, and the final stage of implementation.</p>
<p>In this module, you'll learn how to:</p>
<ul>
<li>Prepare for go-live.</li>
<li>Complete the Lifecycle Services methodology.</li>
<li>Perform User acceptance testing (UAT) for your solution.</li>
<li>Understand the FastTrack Go-live assessment.</li>
<li>Request the production environment.</li>
</ul>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Understand the go-live process</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>The go-live process is shown in the following image.</p>
<p><img alt="Diagram of the go-live process with actions highlighted." data-linktype="relative-path" src="./rawmb500/media_go_live_process.png"/></p>
<p>The go-live process consists of the following actions, which should be considered as sequential steps in a checklist:</p>
<ol>
<li><p><strong>Update the go-live date in Lifecycle Services</strong>: Throughout project implementation, make sure that the milestone dates are continuously kept up-to-date. Start this step, at the latest, two to three months prior to go-live. You need to closely engage with customer key stake holders during this period in case anything unusual happens</p>
</li>
<li><p><strong>Complete and send Pre go-live checklist</strong>: You can perform this task after all User Acceptance Tests (UATs) are completed and signed off by key stakeholders. All finance and operations apps customers must complete a go-live assessment with the Microsoft FastTrack team before their production environment can be deployed. This assessment should be successfully completed before you request your production environment. If you aren't familiar with Microsoft FastTrack, refer to <a data-linktype="absolute-path" href="/en-us/dynamics365/fasttrack/?azure-portal=true">Welcome to FastTrack for Dynamics 365</a>. You can also download the checklist from <a data-linktype="external" href="https://www.microsoft.com/fasttrack/resources/?azure-portal=true">FastTrack Resources page</a>.</p>
</li>
<li><p><strong>Project assessment (Fast Track Essentials)</strong>: The architect will deliver the assessment after the checklist is received and will then continue reviewing until questions are clarified and mitigations are in place, if applicable. It should take a few days for the initial report, plus additional time for mitigation, if necessary. This task is a responsibility of a FastTrack Architect.	<strong>Project workshop (FastTrack)</strong>: A FastTrack Architect uses a project workshop to coordinate activities for assessment.</p>
</li>
<li><p><strong>Release for production deployment</strong>: If the production deployment request has already been submitted, deployment will start. However, we request that you only submit the production request after the assessment has successfully completed. Perform this task upon a successfully completed assessment.</p>
</li>
<li><p><strong>Request production deployment</strong>: This is a self-service task and the responsibility of your customer, though it can be done with your help. The customer should request the production deployment and submit it to Microsoft only after the FastTrack Architect has finished the assessment.</p>
<p>As an earlier part of this step, the sizing team should have informed the customer about the topology needed in a pricing option. Automatic sizing is based on a subscription estimate by default, while manual sizing is based on exception.</p>
<p>In the case of automatic sizing, the timing for sizing is immediate, but it could take longer if it requires further clarification of the subscription estimate.</p>
<p>Finally, the Dynamics Service Engineering (DSE) team performs the deployment, which can take up to 48 hours to complete. The <strong>Status</strong> field in Lifecycle Services reflects the deployment progress. Any questions that you might have about your request will be posted as comments on the service request.</p>
</li>
<li><p><strong>Submit deployable package installation request</strong>: Your customer should be aware that applying packages causes system downtime. All relevant services will be stopped, and they won't be able to use the environments while the package is being applied. You should plan accordingly and perhaps perform this task during off hours.
For package installation, depending on number of packages, it could take a minimum of five hours lead time and four hours downtime for each package.</p>
<p>Generally, 95 percent of the updates are applied in less than one hour; however, we still recommend that you provide a downtime window of four hours in case a rollback is required for any reason.</p>
<p>When the package deployment succeeds, the environment will be available as soon as the package deployment has finished, which means that the longer downtime window does not have any negative effect on system availability.</p>
</li>
<li><p><strong>Submit request to copy database from sandbox (if applicable)</strong>: You need to follow the instructions exactly as they are documented in <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/database/database-refresh/?azure-portal=true">Refresh database</a>.</p>
<p>Also, you need to request <strong>copy database</strong> to restore it to the sandbox environment. Once requested, Dynamics Service Engineering (DSE) will copy the production database and make it available in the Lifecycle Services project’s asset library. Note that it might need five hours lead time and result in two hours downtime.</p>
<p>Generally, the database copy is completed in less than one hour. We still recommend that you provide a downtime window of two hours in case a rollback is required for any reason.</p>
</li>
<li><p><strong>Production ready</strong>: In this task, you and your customer can take control of the production environment after all previous steps have been completed. Depending on the project, some cutover activities might need to be performed.</p>
</li>
<li><p><strong>Go-live</strong>: Depending on the project, the customer can go live with finance and operations apps, hosted in the production environment.</p>
</li>
</ol>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Complete the Lifecycle Services methodology</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>After you have prepared to go live, it is time to take finance and operations apps to the production environment.</p>
<p>Completing the Lifecycle Services methodology is a major milestone in each implementation project, and it is the cutover to the production environment.</p>
<p>To help ensure that the production environment is used for live operations, Microsoft will provision the production instance only when the implementation is approaching the Operate phase, after the required activities in the Lifecycle Services methodology are completed.</p>
<p>For more information about the environments in your subscription, refer to the <a data-linktype="external" href="https://dynamics.microsoft.com/pricing/?azure-portal=true">Licensing guide</a>.</p>
<p>Customers must complete the Analysis, Design and develop, and Test phases in the Lifecycle Services methodology before the <strong>Configure</strong> button that is used to request the production environment becomes available.</p>
<p>To complete a phase in Lifecycle Services, you first need to complete every required step in that phase. When all steps in a phase are completed, you can complete the whole phase. You can always reopen a phase later if you need to make changes.</p>
<p>If you require more help, refer to <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/lifecycle-services/lcs-works-lcs/?azure-portal=true">Lifecycle Services for finance and operations apps customers</a>.</p>
<p>The process of completing a step has two parts:</p>
<ol>
<li>Performing the actual work, such as a fit-gap analysis or user acceptance testing (UAT).</li>
<li>Selecting the corresponding step in the Lifecycle Services methodology as completed.</li>
</ol>
<p>It's good practice to complete the steps in the methodology as you make progress with the implementation. Avoid waiting until the last minute. Be thorough, rather than simply selecting through all the steps to quickly get a production environment. It's in the customer's best interest to have a solid implementation.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Perform user acceptance testing (UAT) for your solution</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>During the User acceptance test (UAT) phase, you need to test all the business processes that you've implemented, and any customizations that you've made, in a sandbox, or standard acceptance test environment, in the implementation project. To help ensure a successful go-live, you should consider the following as you complete the UAT phase:</p>
<ul>
<li>Test that cases cover the entire scope of requirements.</li>
<li>Test by using migrated data. This data should include master data and opening balances, even if they aren't yet final.</li>
<li>Test by using the correct security roles (default roles and custom roles) that are assigned to users.</li>
<li>Make sure that the solution complies with any company-specific and industry-specific regulatory requirements.</li>
<li>Document all features and obtain approval and sign-off from the customer.</li>
</ul>
<p>Regardless of whether the instance of finance and operations apps used for testing is a cloud-hosted environment or a downloaded virtual hard disk (VHD), testing cannot be considered complete because it might have also been used by a developer or other user for demo and training.</p>
<p>The following are the reasons why testing cannot be considered complete:</p>
<ul>
<li>The topology of the Tier-1 environments differs from the topology of your production environment. It's important that you test all functionality on a Tier-2 or higher sandbox environment in the Microsoft-managed subscription. It's especially important that you test integrations, printing functionality, workflow functionality, and warehouse and retail devices in the sandbox environment.</li>
<li>System performance can't be measured when you do the UAT on local virtual machines (VMs) or VMs that are privately hosted.</li>
<li>To prevent delays during the cutover process, it's important that the team experience the servicing in Lifecycle Services during implementation. This servicing includes the processes of applying deployable packages, creating service requests, and moving databases between environments.</li>
</ul>
<p>For more information about User Acceptance Testing (UAT), see  <a data-linktype="absolute-path" href="/en-us/training/modules/perform-uat-finance-operations/?azure-portal=true">Perform user acceptance testing in finance and operations apps</a>.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">FastTrack go-live assessment</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>Microsoft FastTrack for finance and operations apps is a customer success service that is designed to help you move smoothly and confidently to finance and operations apps so that you can realize business value faster.</p>
<p>When participating in the FastTrack program, you receive guidance about implementation best practices, planning for successful rollouts, and expanding capabilities. However, you can implement at your own pace. You also have access to Microsoft Solution Architects who are committed to making your experience with finance and operations apps a success.</p>
<p>All finance and operations apps customers need to complete a go-live review with the Microsoft FastTrack team before their production environment can be deployed. This assessment should be successfully completed before you request your Production environment.
If you aren't familiar with Microsoft FastTrack, go to <a data-linktype="absolute-path" href="/en-us/dynamics365/fasttrack/?azure-portal=true">Welcome to FastTrack for Dynamics 365</a>.</p>
<p>About eight weeks before go-live, the FastTrack team will ask you to fill in a go-live checklist:</p>
<ul>
<li>If you have a combined annual adjusted revenue of 300,000 U.S.Dollars (USD) or more, a Microsoft Solution Architect is assigned to your project, who drives various workshops with Customer and Partner during the implementation.</li>
<li>If you a combined annual adjusted revenue less than 300,000 USD, all the communication with the FastTrack team is via email.</li>
</ul>
<p>To learn more about FastTrack eligibility, review the <a data-linktype="absolute-path" href="/en-us/dynamics365/fasttrack/eligibility/?azure-portal=true">Customer eligibility and partner qualifications</a>.</p>
<p>You can also download a FastTrack pre-go-live checklist.</p>
<p>The project manager or a key project member needs to complete the go-live checklist during the pre-go-live phase of the project. Typically, the checklist is completed four to six weeks before the proposed go-live date, when UAT is completed or almost completed.</p>
<p>After the checklist is submitted, a Microsoft solution architect will review the project and provide an assessment that describes the potential risks, best practices, and recommendations for a successful go-live of the project. In some cases, the Solution Architect might highlight risk factors and ask for a mitigation plan. When the assessment is completed, the Solution Architect will indicate that you're ready to request the production environment in Lifecycle Services.</p>
<p>If you request the production environment before the assessment is completed, the deployment will remain in the <strong>Queued</strong> state until the assessment is successfully completed.</p>
<p>You can cancel an environment deployment request while it is in a <strong>Queued</strong> state by following these steps:</p>
<ol>
<li>Select <strong>Queued</strong>.</li>
<li>On the <strong>Customer sign-off</strong> tab, select <strong>Clear sign-off</strong>.</li>
</ol>
<p>This will set the environment back into a state of Configure and allow you to make changes to the configuration, such as selecting a different datacenter or environment topology.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Request a production environment</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>After you've completed the analysis, design and develop, and test phases in the Lifecycle Services methodology, and the go-live assessment has concluded that the project is ready, you can request your production environment.</p>
<p>We recommend that you select a service account, for example a generic user account, as the Admin user of the environments that you deploy. If you use a named user account, you might not be able to access an environment if that user isn't available.</p>
<p>The following are scenarios where the Admin user needs to access an environment:</p>
<ul>
<li><strong>First sign in to any environment after initial deployment</strong> – In this case, the Admin user is the only user who can access the environment.</li>
<li><strong>First sign in to a sandbox environment after a database refresh from the production environment</strong> – In this case, all user accounts except the Admin account are unable to sign in.</li>
</ul>
<p>Your production environment should be deployed to the same datacenter where your sandbox environments are deployed.</p>
<p>After you've signed off on the request for the production environment, Microsoft is responsible for deploying the production environment for you. The Microsoft service level agreement (SLA) for deployment of a production environment is 48 hours. The production environment can be deployed at any time within 48 hours after you submit the request, provided that your usage profile doesn't require additional information. You can view the progress of the deployment in Lifecycle Services. Typically, the status of the production environment request remains <strong>Queued</strong> for a few hours before it's changed to <strong>Deploying</strong>.</p>
<p>When you submit the deployment request, a service request for the Microsoft Dynamics Service Engineering (DSE) team is automatically created.
You can view this service request in the Service requests list in Lifecycle Services. If the DSE team has questions that prevent them from deploying the production environment, they will add a comment to the service request.</p>
<p>For example, the DSE team might ask that you update the subscription estimate or change the datacenter. In some cases, you might have to clear the sign-off from the production deployment request to make changes.</p>
<p>You can clear the sign-off only while the status of the production environment request is <strong>Queued</strong>. To clear the sign-off, select the <strong>Queued</strong> button. The status of the request is returned to <strong>Configure</strong>. You can then make any changes that are required and sign-off again.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Check your knowledge</h1>
<div hidden="" id="module-unit-notification-container"></div>
<h2>Answer the following questions to see what you've learned</h2>
<form aria-label="Knowledge check" class="quiz-form margin-top-xs" data-bi-name="quiz" role="form">
<fieldset class="field">
<div role="list">
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-1" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-1">
<span class="font-weight-semibold">1.</span>
<p>Your customer is ready to go live and request to deploy the production environment. What must be done first?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-0">
<input class="radio-dot choice-input" id="quiz-choice-0-0" name="0" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>You must deploy a new environment and call it production.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-1">
<input class="radio-dot choice-input" id="quiz-choice-0-1" name="0" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Contact Dynamics Service Engineering (DSE).</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-0-2">
<input class="radio-dot choice-input" id="quiz-choice-0-2" name="0" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Complete a go-live review with the Microsoft FastTrack team.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-2" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-2">
<span class="font-weight-semibold">2.</span>
<p>Your customer is ready to go live and request to deploy the production environment by contacting the Microsoft FastTrack team. What happens next?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-0">
<input class="radio-dot choice-input" id="quiz-choice-1-0" name="1" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>Your production environment is deployed by the Microsoft FastTrack team.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-1">
<input class="radio-dot choice-input" id="quiz-choice-1-1" name="1" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Your production environment is deployed by Dynamics Service Engineering (DSE).</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-1-2">
<input class="radio-dot choice-input" id="quiz-choice-1-2" name="1" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>The Microsoft FastTrack team reviews the project and provides an assessment.</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
<div class="quiz-question" data-bi-name="question" role="listitem">
<div aria-labelledby="quiz-question-3" class="quiz-question-title font-size-md margin-top-sm margin-bottom-xs" role="radiogroup">
<div class="margin-top-sm margin-bottom-xs field-label" id="quiz-question-3">
<span class="font-weight-semibold">3.</span>
<p>Your customer requests a copy database to be restored to a sandbox environment. Who is responsible for this process?</p>
<span class="required-indicator"></span>
</div>
<div class="field-body">
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-0">
<input class="radio-dot choice-input" id="quiz-choice-2-0" name="2" type="radio" value="0"/>
<div class="margin-inline-sm radio-label-text">
<p>SQL Server administrator</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-1">
<input class="radio-dot choice-input" id="quiz-choice-2-1" name="2" type="radio" value="1"/>
<div class="margin-inline-sm radio-label-text">
<p>Microsoft FastTrack team</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
<label class="quiz-choice display-flex padding-block-xxs padding-inline-xs margin-bottom-xxs radio" for="quiz-choice-2-2">
<input class="radio-dot choice-input" id="quiz-choice-2-2" name="2" type="radio" value="2"/>
<div class="margin-inline-sm radio-label-text">
<p>Dynamics Service Engineering (DSE)</p>
</div>
</label>
<div class="quiz-choice-explanation margin-block-xxs font-weight-semibold margin-left-lg">
</div>
</div>
</div>
</div>
</div>
<div class="has-loading-skeleton" id="module-unit-quiz-submit-container"></div>
<p class="font-size-sm color-danger font-weight-semibold margin-top-xxs is-hidden" id="unanswered-question-error" role="alert">You must answer all questions before checking your work.</p>
<p class="visually-hidden" id="screen-reader-text"></p>
</fieldset>
</form>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
<div class="section is-uniform position-relative" id="unit-inner-section">
<h1 class="margin-right-xxl-desktop" id="module-unit-title">Summary</h1>
<div hidden="" id="module-unit-notification-container"></div>
<p>You have now learned how to prepare for a successful go-live by completing the Lifecycle Services methodology and making sure that the customer has performed and signed off on all user acceptance tests.</p>
<p>You also learned about the FastTrack go-live assessment and how to assist the customer to request the production environment.</p>
<p>If you need to understand how to upgrade customers that are currently using Microsoft Dynamics AX 2012, see <a data-linktype="absolute-path" href="/en-us/dynamics365/fin-ops-core/dev-itpro/migration-upgrade/upgrade-overview-2012/?azure-portal=true">Upgrade from AX 2012 to finance and operations</a>.</p>
<div class="modular-content-container" hidden="" id="next-section">
</div>
</div>
